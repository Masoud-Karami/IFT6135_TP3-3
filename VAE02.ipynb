{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VAE.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "a-HwxN4Iyg_j",
        "colab_type": "code",
        "outputId": "645c4127-0bbd-4eae-a71a-d087ae939644",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        }
      },
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Tue Apr 16 09:52:14 2019\n",
        "\n",
        "@author: karm2204\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "#####         https://chrisorm.github.io/VAE-pyt.html\n",
        "#             Variational Autoencoder in Pytorch\n",
        "#             https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/03-advanced/variational_autoencoder/main.py\n",
        "#             https://github.com/bobchennan/VAE_NBP/blob/master/vae_dp.py\n",
        "#             https://github.com/pytorch/examples/blob/master/vae/main.py\n",
        "\n",
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets\n",
        "from torchvision.utils import save_image\n",
        "from torch.autograd import Variable\n",
        "from sklearn.mixture import BayesianGaussianMixture\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import argparse\n",
        "from torchvision.datasets import utils\n",
        "import torch.utils.data as data_utils\n",
        "import torch\n",
        "import os\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from torch.nn.modules import upsampling\n",
        "from torch.functional import F\n",
        "from torch.optim import Adam\n",
        "\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "# Hyper-parameters\n",
        "batch_size = 128\n",
        "learning_rate = 31e-4\n",
        "image_size = 784\n",
        "h_dim = 400\n",
        "z_dim = 100\n",
        "num_epochs = 20\n",
        "\n",
        "\n",
        "#%%\n",
        "\n",
        "def get_data_loader(dataset_location, batch_size):\n",
        "    URL = \"http://www.cs.toronto.edu/~larocheh/public/datasets/binarized_mnist/\"\n",
        "    # start processing\n",
        "    def lines_to_np_array(lines):\n",
        "        return np.array([[int(i) for i in line.split()] for line in lines])\n",
        "    splitdata = []\n",
        "    for splitname in [\"train\", \"valid\", \"test\"]:\n",
        "        filename = \"binarized_mnist_%s.amat\" % splitname\n",
        "        filepath = os.path.join(dataset_location, filename)\n",
        "        utils.download_url(URL + filename, dataset_location)\n",
        "        with open(filepath) as f:\n",
        "            lines = f.readlines()\n",
        "        x = lines_to_np_array(lines).astype('float32')\n",
        "        x = x.reshape(x.shape[0], 1, 28, 28)\n",
        "        # pytorch data loader\n",
        "        dataset = data_utils.TensorDataset(torch.from_numpy(x))\n",
        "        dataset_loader = data_utils.DataLoader(x, batch_size=batch_size, shuffle=splitname == \"train\")\n",
        "        splitdata.append(dataset_loader)\n",
        "    return splitdata\n",
        "\n",
        "train_loader, valid_loader, test_loader = get_data_loader(\"binarized_mnist\", batch_size)\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "for x in train_loader:\n",
        "    plt.imshow(x[0, 0])\n",
        "    break\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using downloaded and verified file: binarized_mnist/binarized_mnist_train.amat\n",
            "Using downloaded and verified file: binarized_mnist/binarized_mnist_valid.amat\n",
            "Using downloaded and verified file: binarized_mnist/binarized_mnist_test.amat\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "sLyvHhhGKshB",
        "colab_type": "code",
        "outputId": "000768ee-6c98-49af-db99-972fb5d9651a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "next(enumerate(train_loader))[1].size()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 1, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "GUfU7LW-1Jut",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#%%\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, image_size=784, h_dim=400, z_dim=100):\n",
        "        super(VAE, self).__init__()\n",
        "        \n",
        "#         self.encoder = nn.Sequential(nn.Linear(image_size, h_dim),\\\n",
        "#                                 nn.ReLU()\\\n",
        "#                                )\n",
        "        self.encoder= nn.Sequential(nn.Conv2d(1,32,3),\\\n",
        "                                    nn.ELU(),\\\n",
        "                                    nn.AvgPool2d(2,2),\\\n",
        "                                    nn.Conv2d(32,64,3),\\\n",
        "                                    nn.ELU(),\\\n",
        "                                    nn.AvgPool2d(2,2),\\\n",
        "                                    nn.Conv2d(64,256,5),\\\n",
        "                                    nn.ELU(),\\\n",
        "                                    )\n",
        "#         self.fc_1 = nn.Linear(image_size, h_dim)\n",
        "        self.fc_1 = nn.Linear(256, z_dim)\n",
        "        self.fc_2 = nn.Linear(256, z_dim)\n",
        "\n",
        "        self.fc_3 = nn.Linear(z_dim, 256)\n",
        "#         self.fc_5 = nn.Linear(h_dim, image_size)\n",
        "        self.decoder= nn.Sequential(nn.ELU(),\\\n",
        "                                    nn.Conv2d(256,64,5, padding = 4),\\\n",
        "                                    nn.ELU(),\\\n",
        "                                    nn.UpsamplingBilinear2d(scale_factor=2),\\\n",
        "                                    nn.Conv2d(64, 32, 3, padding=2),\\\n",
        "                                    nn.ELU(),\\\n",
        "                                    nn.UpsamplingBilinear2d(scale_factor=2),\\\n",
        "                                    nn.Conv2d(32, 16, 3, padding=2),\\\n",
        "                                    nn.ELU(),\\\n",
        "                                    nn.Conv2d(16, 1, 3, padding=2),\\\n",
        "                                    nn.Sigmoid()\n",
        "                                    )\n",
        "        \n",
        "    \"\"\" Encode a batch of samples, and return posterior parameters for each point.\"\"\"    \n",
        "    def encode(self, x):\n",
        "#         h_1 = F.relu(self.fc_1(x))\n",
        "      h_1 = self.encoder(x)\n",
        "      return self.fc_1(h_1.view(-1,256)), self.fc_2(h_1.view(-1,256))\n",
        "\n",
        "\n",
        "    \"\"\" Reparameterisation trick to sample z values. \n",
        "        This is stochastic during training,  and returns the mode during evaluation.\n",
        "        For each training sample (we get 128 batched at a time)\n",
        "        - take the current learned mu, stddev for each of the z_dim \n",
        "        (in the pytorch VAE example, this is 20, z_dim = 20)\n",
        "          dimensions and draw a random sample from that distribution\n",
        "        - the whole network is trained so that these randomly drawn\n",
        "          samples decode to output that looks like the input\n",
        "        - which will mean that the std, mu will be learned\n",
        "          *distributions* that correctly encode the inputs\n",
        "        - due to the additional KLD term (see loss_function() below)\n",
        "          the distribution will tend to unit Gaussians\n",
        "        Parameters\n",
        "        ----------\n",
        "        mu : [128, z_dim] mean matrix\n",
        "        logvar : [128, z_dim] variance matrix\n",
        "        Returns\n",
        "        -------\n",
        "        During training random sample from the learned ZDIMS-dimensional\n",
        "        normal distribution; during inference its mean.\n",
        "        \"\"\"\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(logvar/2)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "\n",
        "    \"\"\" Decode a batch of latent variables\"\"\"\n",
        "    def decode(self, z):\n",
        "    #        h_3 = F.relu(self.fc_4(z))\n",
        "    #        return F.sigmoid(self.fc_5(h_3))\n",
        "        h_2 = self.fc_3(z).view(-1,256,1,1)\n",
        "        h_3 = self.decoder(h_2)\n",
        "        return h_3\n",
        "\n",
        "\n",
        "    \"\"\" Takes a batch of samples, encodes them, and then decodes them again to compare.\"\"\"\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decode(z), mu, logvar\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ywvLbrAtzHaM",
        "colab_type": "code",
        "outputId": "ed55c946-60a4-49bd-df3b-69055cb7d845",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2312
        }
      },
      "cell_type": "code",
      "source": [
        "#%%\n",
        "model = VAE().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\"\"\" ELBO assuming entries of x are binary variables, with closed form KLD.\"\"\"\n",
        "def loss_function(x_reconst, x, mu, logvar):\n",
        "    bce = F.binary_cross_entropy(x_reconst, x.view(-1, 784), reduction='sum')\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    # Normalise by same number of elements as in reconstruction\n",
        "    # KLD /= x.view(-1, image_size).data.shape[0] * image_size\n",
        "    return bce + KLD\n",
        "#%%\n",
        "\n",
        "# ----------\n",
        "#  Train\n",
        "# ----------\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    log_interval = 100\n",
        "    for batch_idx, data in enumerate(train_loader):\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        recon_batch, mu, logvar = model(data)\n",
        "        loss = loss_function(recon_batch, data, mu, logvar)\n",
        "        loss.backward()\n",
        "        train_loss += loss.item()\n",
        "        optimizer.step()\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\t Loss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset), 100. *\n",
        "                batch_idx / len(train_loader), loss.item() / len(data)\n",
        "            ))\n",
        "\n",
        "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
        "        epoch, train_loss / len(train_loader.dataset)))\n",
        "\n",
        "#%%\n",
        "\n",
        "# ----------\n",
        "#  Test\n",
        "# ----------\n",
        "def test(epoch):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    # ind = np.arange(x.shape[0])\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(valid_loader):\n",
        "            data = data.to(device)\n",
        "#           test_data = torch.from_numpy(test_data[np.random.choice(ind, size=batch_size)])\n",
        "#           test_data = Variable(test_data, requires_grad=False)\n",
        "            reconst_batch, mu, logvar = model(data)\n",
        "            test_loss += loss_function(reconst_batch, data, mu, logvar).item()\n",
        "            if i == 0:\n",
        "                n = min(data.size(0), 28)\n",
        "                comparison = torch.cat([data[:n],\n",
        "                                        reconst_batch.view(128, 1, 28, 28)[:n]])\n",
        "#                 save_image(comparison.cpu(),\n",
        "#                          'results/reconstruction_' + str(epoch) + '.png', nrow=n)\n",
        "#            print(data.view(batch_size, 2,2)[:n])\n",
        "#            print(reconst_batch.view(batch_size, 2,2)[:n])\n",
        "            \n",
        "            \n",
        "    test_loss /= len(valid_loader.dataset)\n",
        "    print('====> Test set loss: {:.4f}'.format(test_loss))\n",
        "        \n",
        "#%%    \n",
        "if __name__ == \"__main__\":\n",
        "    for epoch in range(1, 21):\n",
        "        train(epoch)\n",
        "        test(epoch)\n",
        "        # 64 sets of random z_dim-float vectors, i.e. 64 locations / MNIST\n",
        "        # digits in latent space\n",
        "        with torch.no_grad():\n",
        "            sample = torch.randn(128, z_dim).to(device)\n",
        "            sample = model.decode(sample).cpu()\n",
        "#             save_image(sample.view(64, 1, 28, 28),\n",
        "#                        'results/sample_' + str(epoch) + '.png')\n",
        "    torch.save(model.state_dict(), 'vae.pth')            \n",
        "            \n",
        "            "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.UpsamplingBilinear2d is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2016: UserWarning: Using a target size (torch.Size([128, 784])) that is different to the input size (torch.Size([128, 1, 28, 28])) is deprecated. Please ensure they have the same size.\n",
            "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/50000 (0%)]\t Loss: 542.836914\n",
            "Train Epoch: 1 [12800/50000 (26%)]\t Loss: 194.689056\n",
            "Train Epoch: 1 [25600/50000 (51%)]\t Loss: 153.315765\n",
            "Train Epoch: 1 [38400/50000 (77%)]\t Loss: 138.516022\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2016: UserWarning: Using a target size (torch.Size([80, 784])) that is different to the input size (torch.Size([80, 1, 28, 28])) is deprecated. Please ensure they have the same size.\n",
            "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "====> Epoch: 1 Average loss: 172.1882\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2016: UserWarning: Using a target size (torch.Size([16, 784])) that is different to the input size (torch.Size([16, 1, 28, 28])) is deprecated. Please ensure they have the same size.\n",
            "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "====> Test set loss: 124.1842\n",
            "Train Epoch: 2 [0/50000 (0%)]\t Loss: 127.390892\n",
            "Train Epoch: 2 [12800/50000 (26%)]\t Loss: 118.126480\n",
            "Train Epoch: 2 [25600/50000 (51%)]\t Loss: 115.278275\n",
            "Train Epoch: 2 [38400/50000 (77%)]\t Loss: 115.700066\n",
            "====> Epoch: 2 Average loss: 115.4474\n",
            "====> Test set loss: 110.0458\n",
            "Train Epoch: 3 [0/50000 (0%)]\t Loss: 110.079872\n",
            "Train Epoch: 3 [12800/50000 (26%)]\t Loss: 105.505157\n",
            "Train Epoch: 3 [25600/50000 (51%)]\t Loss: 108.556976\n",
            "Train Epoch: 3 [38400/50000 (77%)]\t Loss: 102.728851\n",
            "====> Epoch: 3 Average loss: 106.6912\n",
            "====> Test set loss: 106.5019\n",
            "Train Epoch: 4 [0/50000 (0%)]\t Loss: 106.464096\n",
            "Train Epoch: 4 [12800/50000 (26%)]\t Loss: 107.817703\n",
            "Train Epoch: 4 [25600/50000 (51%)]\t Loss: 101.382286\n",
            "Train Epoch: 4 [38400/50000 (77%)]\t Loss: 101.188065\n",
            "====> Epoch: 4 Average loss: 103.3573\n",
            "====> Test set loss: 103.0445\n",
            "Train Epoch: 5 [0/50000 (0%)]\t Loss: 102.834038\n",
            "Train Epoch: 5 [12800/50000 (26%)]\t Loss: 99.405121\n",
            "Train Epoch: 5 [25600/50000 (51%)]\t Loss: 101.710304\n",
            "Train Epoch: 5 [38400/50000 (77%)]\t Loss: 103.455978\n",
            "====> Epoch: 5 Average loss: 101.3025\n",
            "====> Test set loss: 102.0942\n",
            "Train Epoch: 6 [0/50000 (0%)]\t Loss: 101.247025\n",
            "Train Epoch: 6 [12800/50000 (26%)]\t Loss: 105.383537\n",
            "Train Epoch: 6 [25600/50000 (51%)]\t Loss: 99.344902\n",
            "Train Epoch: 6 [38400/50000 (77%)]\t Loss: 101.899963\n",
            "====> Epoch: 6 Average loss: 100.0758\n",
            "====> Test set loss: 100.5719\n",
            "Train Epoch: 7 [0/50000 (0%)]\t Loss: 99.174858\n",
            "Train Epoch: 7 [12800/50000 (26%)]\t Loss: 97.428688\n",
            "Train Epoch: 7 [25600/50000 (51%)]\t Loss: 96.938461\n",
            "Train Epoch: 7 [38400/50000 (77%)]\t Loss: 102.599365\n",
            "====> Epoch: 7 Average loss: 99.1854\n",
            "====> Test set loss: 99.8188\n",
            "Train Epoch: 8 [0/50000 (0%)]\t Loss: 100.083855\n",
            "Train Epoch: 8 [12800/50000 (26%)]\t Loss: 98.574318\n",
            "Train Epoch: 8 [25600/50000 (51%)]\t Loss: 97.572342\n",
            "Train Epoch: 8 [38400/50000 (77%)]\t Loss: 99.242340\n",
            "====> Epoch: 8 Average loss: 98.5751\n",
            "====> Test set loss: 99.3992\n",
            "Train Epoch: 9 [0/50000 (0%)]\t Loss: 95.953476\n",
            "Train Epoch: 9 [12800/50000 (26%)]\t Loss: 102.118080\n",
            "Train Epoch: 9 [25600/50000 (51%)]\t Loss: 96.291290\n",
            "Train Epoch: 9 [38400/50000 (77%)]\t Loss: 97.811554\n",
            "====> Epoch: 9 Average loss: 97.7654\n",
            "====> Test set loss: 98.9318\n",
            "Train Epoch: 10 [0/50000 (0%)]\t Loss: 96.751152\n",
            "Train Epoch: 10 [12800/50000 (26%)]\t Loss: 96.400650\n",
            "Train Epoch: 10 [25600/50000 (51%)]\t Loss: 94.627487\n",
            "Train Epoch: 10 [38400/50000 (77%)]\t Loss: 95.820702\n",
            "====> Epoch: 10 Average loss: 97.4192\n",
            "====> Test set loss: 98.2601\n",
            "Train Epoch: 11 [0/50000 (0%)]\t Loss: 100.614143\n",
            "Train Epoch: 11 [12800/50000 (26%)]\t Loss: 100.264557\n",
            "Train Epoch: 11 [25600/50000 (51%)]\t Loss: 93.620003\n",
            "Train Epoch: 11 [38400/50000 (77%)]\t Loss: 101.121422\n",
            "====> Epoch: 11 Average loss: 97.1219\n",
            "====> Test set loss: 97.5535\n",
            "Train Epoch: 12 [0/50000 (0%)]\t Loss: 94.572632\n",
            "Train Epoch: 12 [12800/50000 (26%)]\t Loss: 96.737648\n",
            "Train Epoch: 12 [25600/50000 (51%)]\t Loss: 96.976379\n",
            "Train Epoch: 12 [38400/50000 (77%)]\t Loss: 96.088249\n",
            "====> Epoch: 12 Average loss: 96.6504\n",
            "====> Test set loss: 96.9505\n",
            "Train Epoch: 13 [0/50000 (0%)]\t Loss: 95.159393\n",
            "Train Epoch: 13 [12800/50000 (26%)]\t Loss: 98.431190\n",
            "Train Epoch: 13 [25600/50000 (51%)]\t Loss: 95.848541\n",
            "Train Epoch: 13 [38400/50000 (77%)]\t Loss: 92.035446\n",
            "====> Epoch: 13 Average loss: 96.2073\n",
            "====> Test set loss: 97.4038\n",
            "Train Epoch: 14 [0/50000 (0%)]\t Loss: 97.142242\n",
            "Train Epoch: 14 [12800/50000 (26%)]\t Loss: 92.434509\n",
            "Train Epoch: 14 [25600/50000 (51%)]\t Loss: 98.040894\n",
            "Train Epoch: 14 [38400/50000 (77%)]\t Loss: 95.542755\n",
            "====> Epoch: 14 Average loss: 96.0200\n",
            "====> Test set loss: 97.0249\n",
            "Train Epoch: 15 [0/50000 (0%)]\t Loss: 96.675293\n",
            "Train Epoch: 15 [12800/50000 (26%)]\t Loss: 93.441566\n",
            "Train Epoch: 15 [25600/50000 (51%)]\t Loss: 99.844940\n",
            "Train Epoch: 15 [38400/50000 (77%)]\t Loss: 93.963501\n",
            "====> Epoch: 15 Average loss: 95.8501\n",
            "====> Test set loss: 98.1474\n",
            "Train Epoch: 16 [0/50000 (0%)]\t Loss: 95.225723\n",
            "Train Epoch: 16 [12800/50000 (26%)]\t Loss: 92.655586\n",
            "Train Epoch: 16 [25600/50000 (51%)]\t Loss: 91.816254\n",
            "Train Epoch: 16 [38400/50000 (77%)]\t Loss: 94.891930\n",
            "====> Epoch: 16 Average loss: 95.7234\n",
            "====> Test set loss: 96.0509\n",
            "Train Epoch: 17 [0/50000 (0%)]\t Loss: 95.099655\n",
            "Train Epoch: 17 [12800/50000 (26%)]\t Loss: 96.565353\n",
            "Train Epoch: 17 [25600/50000 (51%)]\t Loss: 95.949905\n",
            "Train Epoch: 17 [38400/50000 (77%)]\t Loss: 99.450310\n",
            "====> Epoch: 17 Average loss: 95.3234\n",
            "====> Test set loss: 97.4366\n",
            "Train Epoch: 18 [0/50000 (0%)]\t Loss: 96.303368\n",
            "Train Epoch: 18 [12800/50000 (26%)]\t Loss: 92.036926\n",
            "Train Epoch: 18 [25600/50000 (51%)]\t Loss: 92.224945\n",
            "Train Epoch: 18 [38400/50000 (77%)]\t Loss: 91.740303\n",
            "====> Epoch: 18 Average loss: 95.1513\n",
            "====> Test set loss: 96.9290\n",
            "Train Epoch: 19 [0/50000 (0%)]\t Loss: 94.744896\n",
            "Train Epoch: 19 [12800/50000 (26%)]\t Loss: 94.042923\n",
            "Train Epoch: 19 [25600/50000 (51%)]\t Loss: 97.283623\n",
            "Train Epoch: 19 [38400/50000 (77%)]\t Loss: 98.939667\n",
            "====> Epoch: 19 Average loss: 95.0100\n",
            "====> Test set loss: 96.0780\n",
            "Train Epoch: 20 [0/50000 (0%)]\t Loss: 100.148209\n",
            "Train Epoch: 20 [12800/50000 (26%)]\t Loss: 96.070747\n",
            "Train Epoch: 20 [25600/50000 (51%)]\t Loss: 95.161407\n",
            "Train Epoch: 20 [38400/50000 (77%)]\t Loss: 98.243439\n",
            "====> Epoch: 20 Average loss: 94.9237\n",
            "====> Test set loss: 95.5496\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NNb53AGRBumY",
        "colab_type": "code",
        "outputId": "c9f31012-29a2-4529-8598-603c9fc3812d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "#let's do it with a single batch of 128, we can adjust later\n",
        "mean_val =  [None]*1000\n",
        "sigma_val = [None]*1000\n",
        "others = [None]*1000\n",
        "\n",
        "for i, data in enumerate(test_loader):\n",
        "  data = data.to(device)\n",
        "  others[i], mean_val[i], sigma_val[i] = model(data)\n",
        "#z_mean, z_log_var = model.encode()\n",
        "\n",
        "mean_val_test = mean_val[0]\n",
        "log_sigma_val_test = sigma_val[0]\n",
        "images = others[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.UpsamplingBilinear2d is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "AfB5pWHN_j9x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sigma_val_test = torch.exp(log_sigma_val_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sh0xIGOnAQHy",
        "colab_type": "code",
        "outputId": "3ad14082-2219-42a5-f79b-3e3fcd7fa78e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "cell_type": "code",
      "source": [
        "standard = torch.distributions.normal.Normal(torch.zeros(128,100).cuda(), torch.ones(128,100).cuda())\n",
        "displaced = torch.distributions.normal.Normal(mean_val_test, log_sigma_val_test)\n",
        "\n",
        "sample = displaced.sample(sample_shape=torch.Size())\n",
        "samples = [displaced.sample(sample_shape=torch.Size()) for i in range(200)]\n",
        "\n",
        "#p and q are (200, 128,100)\n",
        "p_samples = torch.stack([torch.exp(standard.log_prob(samples[i])) for i in range(len(samples))])\n",
        "q_samples = torch.stack([torch.exp(displaced.log_prob(samples[i])) for i in range(len(samples))])\n",
        "\n",
        "#torch.Size([200, 128, 784])\n",
        "reconstructions = torch.stack([model.decode(p_samples[i]).view(-1,784) for i in range(200)])\n",
        "\n",
        "\n",
        "#decode a minibatch of samples for all K\n",
        "second = images.view(-1,784)\n",
        "loss_fc = torch.nn.BCELoss(reduction = 'sum')\n",
        "\n",
        "((second * torch.log(reconstructions[0])) + ((1-second)*torch.log(1-reconstructions[0]))).size()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.UpsamplingBilinear2d is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 784])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "8XVJncr9LAdU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# first = model.decode(p_samples[0]).view(-1,784)\n",
        "# second = model.decode(p_samples[1]).view(-1,784)\n",
        "# torch.stack([first,second]).size()\n",
        "torch.log(reconstructions).size()\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
