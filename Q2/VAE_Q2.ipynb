{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VAE_Q2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "a-HwxN4Iyg_j",
        "colab_type": "code",
        "outputId": "ab659dec-7bae-4797-d2e2-abb22a6b0424",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Tue Apr 16 09:52:14 2019\n",
        "\n",
        "@author: karm2204\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "#####         https://chrisorm.github.io/VAE-pyt.html\n",
        "#             Variational Autoencoder in Pytorch\n",
        "#             https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/03-advanced/variational_autoencoder/main.py\n",
        "#             https://github.com/bobchennan/VAE_NBP/blob/master/vae_dp.py\n",
        "#             https://github.com/pytorch/examples/blob/master/vae/main.py\n",
        "\n",
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets\n",
        "from torchvision.utils import save_image\n",
        "from torch.autograd import Variable\n",
        "from sklearn.mixture import BayesianGaussianMixture\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import argparse\n",
        "from torchvision.datasets import utils\n",
        "import torch.utils.data as data_utils\n",
        "import torch\n",
        "import os\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from torch.nn.modules import upsampling\n",
        "from torch.functional import F\n",
        "from torch.optim import Adam\n",
        "\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.set_printoptions(precision=8)\n",
        "\n",
        "\n",
        "# Hyper-parameters\n",
        "batch_size = 128\n",
        "learning_rate = 3e-4\n",
        "image_size = 784\n",
        "h_dim = 400\n",
        "z_dim = 100\n",
        "num_epochs = 20\n",
        "\n",
        "\n",
        "#%%\n",
        "\n",
        "def get_data_loader(dataset_location, batch_size):\n",
        "    URL = \"http://www.cs.toronto.edu/~larocheh/public/datasets/binarized_mnist/\"\n",
        "    # start processing\n",
        "    def lines_to_np_array(lines):\n",
        "        return np.array([[int(i) for i in line.split()] for line in lines])\n",
        "    splitdata = []\n",
        "    for splitname in [\"train\", \"valid\", \"test\"]:\n",
        "        filename = \"binarized_mnist_%s.amat\" % splitname\n",
        "        filepath = os.path.join(dataset_location, filename)\n",
        "        utils.download_url(URL + filename, dataset_location)\n",
        "        with open(filepath) as f:\n",
        "            lines = f.readlines()\n",
        "        x = lines_to_np_array(lines).astype('float32')\n",
        "        x = x.reshape(x.shape[0], 1, 28, 28)\n",
        "        # pytorch data loader\n",
        "        dataset = data_utils.TensorDataset(torch.from_numpy(x))\n",
        "        dataset_loader = data_utils.DataLoader(x, batch_size=batch_size, shuffle=splitname == \"train\")\n",
        "        splitdata.append(dataset_loader)\n",
        "    return splitdata\n",
        "\n",
        "train_loader, valid_loader, test_loader = get_data_loader(\"binarized_mnist\", batch_size)\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "for x in train_loader:\n",
        "    plt.imshow(x[0, 0])\n",
        "    break\n",
        "    \n",
        "torch.cuda.memory_allocated(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using downloaded and verified file: binarized_mnist/binarized_mnist_train.amat\n",
            "Using downloaded and verified file: binarized_mnist/binarized_mnist_valid.amat\n",
            "Using downloaded and verified file: binarized_mnist/binarized_mnist_test.amat\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nv1SU4ZeK+h9lb9Sfbwt6rwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "sLyvHhhGKshB",
        "colab_type": "code",
        "outputId": "caf5c3fd-0758-4e3a-d3ed-70dd8ef2157b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "next(enumerate(train_loader))[1].size()\n",
        "torch.cuda.memory_allocated(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "GUfU7LW-1Jut",
        "colab_type": "code",
        "outputId": "b36109ab-d2a7-4963-fbfb-014019aaccea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#%%\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, image_size=784, h_dim=400, z_dim=100):\n",
        "        super(VAE, self).__init__()\n",
        "        \n",
        "#         self.encoder = nn.Sequential(nn.Linear(image_size, h_dim),\\\n",
        "#                                 nn.ReLU()\\\n",
        "#                                )\n",
        "        self.encoder= nn.Sequential(nn.Conv2d(1,32,3),\\\n",
        "                                    nn.ELU(),\\\n",
        "                                    nn.AvgPool2d(2,2),\\\n",
        "                                    nn.Conv2d(32,64,3),\\\n",
        "                                    nn.ELU(),\\\n",
        "                                    nn.AvgPool2d(2,2),\\\n",
        "                                    nn.Conv2d(64,256,5),\\\n",
        "                                    nn.ELU(),\\\n",
        "                                    )\n",
        "#         self.fc_1 = nn.Linear(image_size, h_dim)\n",
        "        self.fc_1 = nn.Linear(256, z_dim)\n",
        "        self.fc_2 = nn.Linear(256, z_dim)\n",
        "\n",
        "        self.fc_3 = nn.Linear(z_dim, 256)\n",
        "#         self.fc_5 = nn.Linear(h_dim, image_size)\n",
        "        self.decoder= nn.Sequential(nn.ELU(),\\\n",
        "                                    nn.Conv2d(256,64,5, padding = 4),\\\n",
        "                                    nn.ELU(),\\\n",
        "                                    nn.UpsamplingBilinear2d(scale_factor=2),\\\n",
        "                                    nn.Conv2d(64, 32, 3, padding=2),\\\n",
        "                                    nn.ELU(),\\\n",
        "                                    nn.UpsamplingBilinear2d(scale_factor=2),\\\n",
        "                                    nn.Conv2d(32, 16, 3, padding=2),\\\n",
        "                                    nn.ELU(),\\\n",
        "                                    nn.Conv2d(16, 1, 3, padding=2),\\\n",
        "                                    nn.Sigmoid()\n",
        "                                    )\n",
        "        \n",
        "    \"\"\" Encode a batch of samples, and return posterior parameters for each point.\"\"\"    \n",
        "    def encode(self, x):\n",
        "#         h_1 = F.relu(self.fc_1(x))\n",
        "      h_1 = self.encoder(x)\n",
        "      return self.fc_1(h_1.view(-1,256)), self.fc_2(h_1.view(-1,256))\n",
        "\n",
        "\n",
        "    \"\"\" Reparameterisation trick to sample z values. \n",
        "        This is stochastic during training,  and returns the mode during evaluation.\n",
        "        For each training sample (we get 128 batched at a time)\n",
        "        - take the current learned mu, stddev for each of the z_dim \n",
        "        (in the pytorch VAE example, this is 20, z_dim = 20)\n",
        "          dimensions and draw a random sample from that distribution\n",
        "        - the whole network is trained so that these randomly drawn\n",
        "          samples decode to output that looks like the input\n",
        "        - which will mean that the std, mu will be learned\n",
        "          *distributions* that correctly encode the inputs\n",
        "        - due to the additional KLD term (see loss_function() below)\n",
        "          the distribution will tend to unit Gaussians\n",
        "        Parameters\n",
        "        ----------\n",
        "        mu : [128, z_dim] mean matrix\n",
        "        logvar : [128, z_dim] variance matrix\n",
        "        Returns\n",
        "        -------\n",
        "        During training random sample from the learned ZDIMS-dimensional\n",
        "        normal distribution; during inference its mean.\n",
        "        \"\"\"\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(logvar/2)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "\n",
        "    \"\"\" Decode a batch of latent variables\"\"\"\n",
        "    def decode(self, z):\n",
        "    #        h_3 = F.relu(self.fc_4(z))\n",
        "    #        return F.sigmoid(self.fc_5(h_3))\n",
        "        h_2 = self.fc_3(z).view(-1,256,1,1)\n",
        "        h_3 = self.decoder(h_2)\n",
        "        return h_3\n",
        "\n",
        "\n",
        "    \"\"\" Takes a batch of samples, encodes them, and then decodes them again to compare.\"\"\"\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decode(z), mu, logvar\n",
        "torch.cuda.memory_allocated(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "ywvLbrAtzHaM",
        "colab_type": "code",
        "outputId": "a6fb4a6b-379f-4b60-fb7f-f36d8a4a603d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2312
        }
      },
      "cell_type": "code",
      "source": [
        "#%%\n",
        "model = VAE().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\"\"\" ELBO assuming entries of x are binary variables, with closed form KLD.\"\"\"\n",
        "def loss_function(x_reconst, x, mu, logvar):\n",
        "    bce = F.binary_cross_entropy(x_reconst, x.view(-1, 784), reduction='sum')\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    # Normalise by same number of elements as in reconstruction\n",
        "    # KLD /= x.view(-1, image_size).data.shape[0] * image_size\n",
        "    return bce + KLD\n",
        "#%%\n",
        "\n",
        "# ----------\n",
        "#  Train\n",
        "# ----------\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    log_interval = 100\n",
        "    for batch_idx, data in enumerate(train_loader):\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        recon_batch, mu, logvar = model(data)\n",
        "        loss = loss_function(recon_batch, data, mu, logvar)\n",
        "        loss.backward()\n",
        "        train_loss += loss.item()\n",
        "        optimizer.step()\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\t Loss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset), 100. *\n",
        "                batch_idx / len(train_loader), -loss.item() / len(data)\n",
        "            ))\n",
        "\n",
        "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
        "        epoch, -train_loss / len(train_loader.dataset)))\n",
        "\n",
        "#%%\n",
        "\n",
        "# ----------\n",
        "#  Test\n",
        "# ----------\n",
        "def test(epoch, data_loader):\n",
        "    model.eval()\n",
        "    valid_loss = 0\n",
        "    # ind = np.arange(x.shape[0])\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(data_loader):\n",
        "            data = data.to(device)\n",
        "#           test_data = torch.from_numpy(test_data[np.random.choice(ind, size=batch_size)])\n",
        "#           test_data = Variable(test_data, requires_grad=False)\n",
        "            reconst_batch, mu, logvar = model(data)\n",
        "            valid_loss += loss_function(reconst_batch, data, mu, logvar).item()\n",
        "            if i == 0:\n",
        "                n = min(data.size(0), 28)\n",
        "                comparison = torch.cat([data[:n],\n",
        "                                        reconst_batch.view(128, 1, 28, 28)[:n]])\n",
        "#                 save_image(comparison.cpu(),\n",
        "#                          'results/reconstruction_' + str(epoch) + '.png', nrow=n)\n",
        "#            print(data.view(batch_size, 2,2)[:n])\n",
        "#            print(reconst_batch.view(batch_size, 2,2)[:n])\n",
        "            \n",
        "            \n",
        "    valid_loss /= len(data_loader.dataset)\n",
        "    print('====> average per-instance ELBO: {:.4f}'.format(-valid_loss))\n",
        "        \n",
        "#%%    \n",
        "if __name__ == \"__main__\":\n",
        "    for epoch in range(1, 21):\n",
        "        train(epoch)\n",
        "        test(epoch, valid_loader)\n",
        "        # 64 sets of random z_dim-float vectors, i.e. 64 locations / MNIST\n",
        "        # digits in latent space\n",
        "        with torch.no_grad():\n",
        "            sample = torch.randn(128, z_dim).to(device)\n",
        "            sample = model.decode(sample).cpu()\n",
        "#             save_image(sample.view(64, 1, 28, 28),\n",
        "#                        'results/sample_' + str(epoch) + '.png')\n",
        "    torch.save(model.state_dict(), 'vae.pth')            \n",
        "            "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.UpsamplingBilinear2d is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2016: UserWarning: Using a target size (torch.Size([128, 784])) that is different to the input size (torch.Size([128, 1, 28, 28])) is deprecated. Please ensure they have the same size.\n",
            "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/50000 (0%)]\t Loss: -555.041565\n",
            "Train Epoch: 1 [12800/50000 (26%)]\t Loss: -211.656952\n",
            "Train Epoch: 1 [25600/50000 (51%)]\t Loss: -186.656479\n",
            "Train Epoch: 1 [38400/50000 (77%)]\t Loss: -163.786179\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2016: UserWarning: Using a target size (torch.Size([80, 784])) that is different to the input size (torch.Size([80, 1, 28, 28])) is deprecated. Please ensure they have the same size.\n",
            "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "====> Epoch: 1 Average loss: -210.9736\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2016: UserWarning: Using a target size (torch.Size([16, 784])) that is different to the input size (torch.Size([16, 1, 28, 28])) is deprecated. Please ensure they have the same size.\n",
            "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "====> average per-instance ELBO: -155.8165\n",
            "Train Epoch: 2 [0/50000 (0%)]\t Loss: -161.116394\n",
            "Train Epoch: 2 [12800/50000 (26%)]\t Loss: -146.289154\n",
            "Train Epoch: 2 [25600/50000 (51%)]\t Loss: -137.686798\n",
            "Train Epoch: 2 [38400/50000 (77%)]\t Loss: -136.730652\n",
            "====> Epoch: 2 Average loss: -140.4270\n",
            "====> average per-instance ELBO: -128.7384\n",
            "Train Epoch: 3 [0/50000 (0%)]\t Loss: -127.036186\n",
            "Train Epoch: 3 [12800/50000 (26%)]\t Loss: -121.848679\n",
            "Train Epoch: 3 [25600/50000 (51%)]\t Loss: -117.619301\n",
            "Train Epoch: 3 [38400/50000 (77%)]\t Loss: -115.348572\n",
            "====> Epoch: 3 Average loss: -121.1624\n",
            "====> average per-instance ELBO: -115.9329\n",
            "Train Epoch: 4 [0/50000 (0%)]\t Loss: -121.895844\n",
            "Train Epoch: 4 [12800/50000 (26%)]\t Loss: -117.232979\n",
            "Train Epoch: 4 [25600/50000 (51%)]\t Loss: -112.204651\n",
            "Train Epoch: 4 [38400/50000 (77%)]\t Loss: -116.309792\n",
            "====> Epoch: 4 Average loss: -112.5370\n",
            "====> average per-instance ELBO: -110.3959\n",
            "Train Epoch: 5 [0/50000 (0%)]\t Loss: -110.254814\n",
            "Train Epoch: 5 [12800/50000 (26%)]\t Loss: -110.994202\n",
            "Train Epoch: 5 [25600/50000 (51%)]\t Loss: -107.379059\n",
            "Train Epoch: 5 [38400/50000 (77%)]\t Loss: -111.142967\n",
            "====> Epoch: 5 Average loss: -108.4217\n",
            "====> average per-instance ELBO: -106.9855\n",
            "Train Epoch: 6 [0/50000 (0%)]\t Loss: -104.120674\n",
            "Train Epoch: 6 [12800/50000 (26%)]\t Loss: -105.974174\n",
            "Train Epoch: 6 [25600/50000 (51%)]\t Loss: -100.307571\n",
            "Train Epoch: 6 [38400/50000 (77%)]\t Loss: -103.147537\n",
            "====> Epoch: 6 Average loss: -105.7594\n",
            "====> average per-instance ELBO: -105.1195\n",
            "Train Epoch: 7 [0/50000 (0%)]\t Loss: -104.357559\n",
            "Train Epoch: 7 [12800/50000 (26%)]\t Loss: -105.162476\n",
            "Train Epoch: 7 [25600/50000 (51%)]\t Loss: -104.569321\n",
            "Train Epoch: 7 [38400/50000 (77%)]\t Loss: -104.319138\n",
            "====> Epoch: 7 Average loss: -103.9632\n",
            "====> average per-instance ELBO: -103.5969\n",
            "Train Epoch: 8 [0/50000 (0%)]\t Loss: -102.516792\n",
            "Train Epoch: 8 [12800/50000 (26%)]\t Loss: -102.777176\n",
            "Train Epoch: 8 [25600/50000 (51%)]\t Loss: -107.597191\n",
            "Train Epoch: 8 [38400/50000 (77%)]\t Loss: -100.672867\n",
            "====> Epoch: 8 Average loss: -102.4131\n",
            "====> average per-instance ELBO: -102.2585\n",
            "Train Epoch: 9 [0/50000 (0%)]\t Loss: -103.905518\n",
            "Train Epoch: 9 [12800/50000 (26%)]\t Loss: -101.158249\n",
            "Train Epoch: 9 [25600/50000 (51%)]\t Loss: -102.152321\n",
            "Train Epoch: 9 [38400/50000 (77%)]\t Loss: -100.212677\n",
            "====> Epoch: 9 Average loss: -101.2172\n",
            "====> average per-instance ELBO: -101.1194\n",
            "Train Epoch: 10 [0/50000 (0%)]\t Loss: -101.727509\n",
            "Train Epoch: 10 [12800/50000 (26%)]\t Loss: -99.514709\n",
            "Train Epoch: 10 [25600/50000 (51%)]\t Loss: -101.483200\n",
            "Train Epoch: 10 [38400/50000 (77%)]\t Loss: -98.242897\n",
            "====> Epoch: 10 Average loss: -100.2394\n",
            "====> average per-instance ELBO: -100.1003\n",
            "Train Epoch: 11 [0/50000 (0%)]\t Loss: -101.652107\n",
            "Train Epoch: 11 [12800/50000 (26%)]\t Loss: -99.299194\n",
            "Train Epoch: 11 [25600/50000 (51%)]\t Loss: -99.846069\n",
            "Train Epoch: 11 [38400/50000 (77%)]\t Loss: -99.872955\n",
            "====> Epoch: 11 Average loss: -99.4412\n",
            "====> average per-instance ELBO: -99.4461\n",
            "Train Epoch: 12 [0/50000 (0%)]\t Loss: -101.309624\n",
            "Train Epoch: 12 [12800/50000 (26%)]\t Loss: -101.572952\n",
            "Train Epoch: 12 [25600/50000 (51%)]\t Loss: -97.302101\n",
            "Train Epoch: 12 [38400/50000 (77%)]\t Loss: -95.778191\n",
            "====> Epoch: 12 Average loss: -98.7376\n",
            "====> average per-instance ELBO: -98.8430\n",
            "Train Epoch: 13 [0/50000 (0%)]\t Loss: -99.916481\n",
            "Train Epoch: 13 [12800/50000 (26%)]\t Loss: -97.968513\n",
            "Train Epoch: 13 [25600/50000 (51%)]\t Loss: -94.247665\n",
            "Train Epoch: 13 [38400/50000 (77%)]\t Loss: -95.313148\n",
            "====> Epoch: 13 Average loss: -98.1258\n",
            "====> average per-instance ELBO: -98.1761\n",
            "Train Epoch: 14 [0/50000 (0%)]\t Loss: -94.521698\n",
            "Train Epoch: 14 [12800/50000 (26%)]\t Loss: -98.030685\n",
            "Train Epoch: 14 [25600/50000 (51%)]\t Loss: -95.281082\n",
            "Train Epoch: 14 [38400/50000 (77%)]\t Loss: -96.351898\n",
            "====> Epoch: 14 Average loss: -97.5207\n",
            "====> average per-instance ELBO: -97.9446\n",
            "Train Epoch: 15 [0/50000 (0%)]\t Loss: -100.837418\n",
            "Train Epoch: 15 [12800/50000 (26%)]\t Loss: -96.136581\n",
            "Train Epoch: 15 [25600/50000 (51%)]\t Loss: -99.216187\n",
            "Train Epoch: 15 [38400/50000 (77%)]\t Loss: -98.574493\n",
            "====> Epoch: 15 Average loss: -97.1182\n",
            "====> average per-instance ELBO: -97.3602\n",
            "Train Epoch: 16 [0/50000 (0%)]\t Loss: -96.582855\n",
            "Train Epoch: 16 [12800/50000 (26%)]\t Loss: -94.949158\n",
            "Train Epoch: 16 [25600/50000 (51%)]\t Loss: -97.287048\n",
            "Train Epoch: 16 [38400/50000 (77%)]\t Loss: -97.766289\n",
            "====> Epoch: 16 Average loss: -96.6204\n",
            "====> average per-instance ELBO: -96.8372\n",
            "Train Epoch: 17 [0/50000 (0%)]\t Loss: -95.783417\n",
            "Train Epoch: 17 [12800/50000 (26%)]\t Loss: -96.837090\n",
            "Train Epoch: 17 [25600/50000 (51%)]\t Loss: -97.267685\n",
            "Train Epoch: 17 [38400/50000 (77%)]\t Loss: -95.582642\n",
            "====> Epoch: 17 Average loss: -96.3110\n",
            "====> average per-instance ELBO: -96.9672\n",
            "Train Epoch: 18 [0/50000 (0%)]\t Loss: -99.587852\n",
            "Train Epoch: 18 [12800/50000 (26%)]\t Loss: -94.879753\n",
            "Train Epoch: 18 [25600/50000 (51%)]\t Loss: -97.995583\n",
            "Train Epoch: 18 [38400/50000 (77%)]\t Loss: -97.537643\n",
            "====> Epoch: 18 Average loss: -95.9660\n",
            "====> average per-instance ELBO: -96.3796\n",
            "Train Epoch: 19 [0/50000 (0%)]\t Loss: -92.990051\n",
            "Train Epoch: 19 [12800/50000 (26%)]\t Loss: -94.888687\n",
            "Train Epoch: 19 [25600/50000 (51%)]\t Loss: -92.695694\n",
            "Train Epoch: 19 [38400/50000 (77%)]\t Loss: -93.638428\n",
            "====> Epoch: 19 Average loss: -95.6008\n",
            "====> average per-instance ELBO: -96.0113\n",
            "Train Epoch: 20 [0/50000 (0%)]\t Loss: -95.270950\n",
            "Train Epoch: 20 [12800/50000 (26%)]\t Loss: -96.822372\n",
            "Train Epoch: 20 [25600/50000 (51%)]\t Loss: -91.529221\n",
            "Train Epoch: 20 [38400/50000 (77%)]\t Loss: -91.748840\n",
            "====> Epoch: 20 Average loss: -95.3308\n",
            "====> average per-instance ELBO: -95.5754\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bDQ3dpFMI9vT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Question 2.1\n",
        "\n",
        "The average per-instance ELBO at the bottom is the average per-instance ELBO on the validaton set."
      ]
    },
    {
      "metadata": {
        "id": "k5jgsPekJzRy",
        "colab_type": "code",
        "outputId": "2f050dca-4fec-4dbb-d053-93a71e398525",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "cell_type": "code",
      "source": [
        "test(20, train_loader)\n",
        "print('for the training set')\n",
        "test(20, valid_loader)\n",
        "print('for the validation set')\n",
        "test(20, test_loader)\n",
        "print('for the test set')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.UpsamplingBilinear2d is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2016: UserWarning: Using a target size (torch.Size([128, 784])) that is different to the input size (torch.Size([128, 1, 28, 28])) is deprecated. Please ensure they have the same size.\n",
            "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2016: UserWarning: Using a target size (torch.Size([80, 784])) that is different to the input size (torch.Size([80, 1, 28, 28])) is deprecated. Please ensure they have the same size.\n",
            "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "====> average per-instance ELBO: -95.1148\n",
            "for the training set\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2016: UserWarning: Using a target size (torch.Size([16, 784])) that is different to the input size (torch.Size([16, 1, 28, 28])) is deprecated. Please ensure they have the same size.\n",
            "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "====> average per-instance ELBO: -95.5620\n",
            "for the validation set\n",
            "====> average per-instance ELBO: -94.8297\n",
            "for the test set\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BndjAQXcLhkE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Train a VAE\n",
        "\n",
        "the training set ELBO:     -95.1148\n",
        "\n",
        "the validation set ELBO: -95.5620\n",
        "\n",
        "The test set ELBO            -94.9080."
      ]
    },
    {
      "metadata": {
        "id": "ilFxgXH4-yTV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Evaluating log-likelihood with Variational Autoencoders 2.1\n",
        "\n",
        "def importance_sampling_minibatch(model, images, samples):\n",
        "  K = 200\n",
        "  hidden_size = 100\n",
        "  minibatch_size = 128\n",
        "  image_dim = 28\n",
        "  image_size = 784\n",
        "  images.to(device)\n",
        "  samples.to(device)\n",
        "  samples = samples.permute(1,0,2)\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    mean_val = torch.mean(samples, dim = 0)\n",
        "    sigma_val = torch.std(samples, dim = 0)\n",
        "\n",
        "    #two distributions, one standard and one displaced \n",
        "    standard = torch.distributions.normal.Normal(torch.zeros(min(minibatch_size,mean_val.size(0)),hidden_size).cuda(),\\\n",
        "                                                 torch.ones(min(minibatch_size,mean_val.size(0)),hidden_size).cuda())\n",
        "    displaced = torch.distributions.normal.Normal(mean_val, sigma_val)\n",
        "\n",
        "#     #sample z x 200 from displaced distribution(mean and s.d. from encoder run on data)\n",
        "#     samples = [displaced.sample(sample_shape=torch.Size()) for i in range(K)]\n",
        "\n",
        "    #p and q are (200, 128,100)\n",
        "    #density values for each samples, for each minibatch, for each uncorrelated z_i\n",
        "    log_p_samples = torch.stack([standard.log_prob(samples[i].data) for i in range(len(samples))])\n",
        "    log_q_samples = torch.stack([displaced.log_prob(samples[i].data) for i in range(len(samples))])\n",
        "\n",
        "    #torch.Size([200, 128, 784]) reconstructions of each sample/minibatch/image\n",
        "    reconstructions = torch.stack([model.decode(samples[i].data).view(-1,image_size) for i in range(K)])\n",
        "\n",
        "    #p of x given z computed with Binary cross entropy \n",
        "    log_p_x_given_z = ((images.view(-1,image_size) * torch.log(torch.clamp(reconstructions.data, 1e-9, 1))) + \\\n",
        "                       ((1.0-images.view(-1,image_size))*torch.log(torch.clamp(1.0-reconstructions.data, 1e-9, 1))))\n",
        "     \n",
        "    #max prob is 1, so max log prob is log(200) for logsumexp trick: \n",
        "    return (-np.log(K) + torch.logsumexp(torch.sum(log_p_x_given_z, dim=-1) + torch.sum(log_p_samples, dim=-1) - \\\n",
        "                                         torch.sum(log_q_samples, dim=-1), 0))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MgpNleoGry9R",
        "colab_type": "code",
        "outputId": "cf069602-6bae-4c14-8451-94e1e0ad8153",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        }
      },
      "cell_type": "code",
      "source": [
        "#Generating own samples for proof that importance_sampling_minibatch works properly\n",
        "temp_images = next(enumerate(valid_loader))[1].view(-1,784).cuda()\n",
        "temp_mu, temp_sigma = model.encode(temp_images.view(-1,1,28,28))\n",
        "temp_sigma = torch.exp(temp_sigma.data/2)\n",
        "\n",
        "standard = torch.distributions.normal.Normal(torch.zeros(128,100).cuda(), torch.ones(128,100).cuda())\n",
        "displaced = torch.distributions.normal.Normal(temp_mu, temp_sigma)\n",
        "samples = [displaced.sample(sample_shape=torch.Size()) for i in range(200)]\n",
        "samples = torch.stack(samples).permute(1,0,2)\n",
        "\n",
        "importance_sampling_minibatch(model, temp_images, samples)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.UpsamplingBilinear2d is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ -95.71740723,  -63.68551254, -111.92938995,  -72.35781097,\n",
              "         -84.92098999,  -97.94902039, -106.89511108,  -72.77054596,\n",
              "         -46.66260529,  -63.53670883,  -97.72489166,  -96.01272583,\n",
              "        -108.42823029,  -94.70073700,  -76.68729401,  -83.60478210,\n",
              "         -53.56590271,  -73.82296753, -109.99315643,  -89.52267456,\n",
              "         -75.71301270,  -85.17124939,  -98.34494781,  -92.26325989,\n",
              "        -108.07697296,  -54.44738007,  -93.37905121,  -48.34919739,\n",
              "        -116.03975677,  -88.53775024,  -42.16527557, -116.36687469,\n",
              "         -72.04990387, -110.46295929,  -55.04835129,  -94.51477814,\n",
              "        -110.25427246,  -95.42953491,  -56.89253998, -107.49494171,\n",
              "         -95.87160492, -109.50654602, -104.27269745, -100.05001068,\n",
              "         -84.35396576,  -99.96205902, -101.85662842, -122.29142761,\n",
              "        -113.62080383,  -86.54142761,  -76.62197876,  -43.35823059,\n",
              "        -110.48961639,  -59.68756866,  -67.32563782,  -87.19290161,\n",
              "         -40.65615082, -107.88906097,  -76.66815186,  -73.15802002,\n",
              "         -95.72063446,  -68.62629700, -115.53807068, -105.90459442,\n",
              "         -67.23842621,  -79.66036224,  -87.70726013,  -85.82482147,\n",
              "         -93.42596436, -102.41816711,  -80.21990204, -110.10641479,\n",
              "         -48.92530823,  -72.46334076,  -45.80054092, -116.24835968,\n",
              "         -82.83421326,  -46.31247711,  -85.46435547,  -72.10692596,\n",
              "        -100.77931976, -114.41811371, -118.38143921,  -87.13324738,\n",
              "        -100.28268433,  -90.02969360,  -98.87768555,  -85.66927338,\n",
              "         -78.55163574,  -85.78139496, -113.20990753,  -79.34964752,\n",
              "         -88.88858795, -112.38219452,  -99.20133209,  -93.73424530,\n",
              "         -81.01017761,  -75.11617279,  -62.89939499, -112.74553680,\n",
              "        -127.29337311, -101.55782318,  -78.86754608,  -88.99289703,\n",
              "         -95.55976105, -123.38130951,  -91.43922424,  -96.34022522,\n",
              "         -84.56596375,  -87.48748016,  -74.44283295,  -71.89260864,\n",
              "         -96.76017761,  -93.50818634,  -74.83956146,  -96.54107666,\n",
              "         -67.40249634,  -63.40478897,  -79.67208862, -103.47483063,\n",
              "         -85.37796021,  -90.56900024,  -94.30204010,  -82.01316071,\n",
              "        -120.22059631, -106.66234589, -112.60184479,  -69.67362976],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "AMT_isebFmLC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For more practical purposes, the following importance sampling function was used instead since it generates its own samples $z_{ik}$."
      ]
    },
    {
      "metadata": {
        "id": "1SNlHGb6Fk82",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def importance_sampling(trained_model, image_loader, minibatch_size, image_size, hidden_size, K):\n",
        "  \n",
        "  log_px = []\n",
        "  with torch.no_grad():\n",
        "\n",
        "    #forward pass through model with image set\n",
        "    for i, data in enumerate(image_loader):\n",
        "      data = data.to(device)\n",
        "      mean_val, log_var_val = model.encode(data)\n",
        "      images = data\n",
        "    #   mean_val_test = mean_val[0].data\n",
        "    #   log_var_val_test = log_var_val[0].data\n",
        "      sigma_val = torch.exp(log_var_val.data/2)\n",
        "\n",
        "      #two distributions, one standard and one displaced \n",
        "      standard = torch.distributions.normal.Normal(torch.zeros(min(minibatch_size,mean_val.size(0)),hidden_size).cuda(),\\\n",
        "                                                   torch.ones(min(minibatch_size,mean_val.size(0)),hidden_size).cuda())\n",
        "      displaced = torch.distributions.normal.Normal(mean_val, sigma_val)\n",
        "\n",
        "      #sample z x 200 from displaced distribution(mean and s.d. from encoder run on data)\n",
        "      #sample = displaced.sample(sample_shape=torch.Size())\n",
        "      samples = [displaced.sample(sample_shape=torch.Size()) for i in range(K)]\n",
        "\n",
        "      #p and q are (200, 128,100)\n",
        "      #density values for each samples, for each minibatch, for each uncorrelated z_i\n",
        "      log_p_samples = torch.stack([standard.log_prob(samples[i].data) for i in range(len(samples))])\n",
        "      log_q_samples = torch.stack([displaced.log_prob(samples[i].data) for i in range(len(samples))])\n",
        "\n",
        "      #torch.Size([200, 128, 784]) reconstructions of each sample/minibatch/image\n",
        "      reconstructions = torch.stack([model.decode(samples[i].data).view(-1,image_size) for i in range(K)])\n",
        "\n",
        "      #p of x given z computed with Binary cross entropy ################# REVIEW DIMENSIONS HERE #####################\n",
        "      log_p_x_given_z = ((images.view(-1,image_size) * torch.log(torch.clamp(reconstructions.data, 1e-9, 1))) + \\\n",
        "                         ((1.0-images.view(-1,image_size))*torch.log(torch.clamp(1.0-reconstructions.data, 1e-9, 1))))\n",
        "\n",
        "      log_px.append( (-np.log(K) + torch.logsumexp(torch.sum(log_p_x_given_z, dim=-1) + \\\n",
        "                                                   torch.sum(log_p_samples, dim=-1) - torch.sum(log_q_samples, dim=-1), 0)))\n",
        "\n",
        "    return torch.cat(log_px)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oL5ukEKLHKmC",
        "colab_type": "code",
        "outputId": "7cccde05-e3de-4102-8ddd-d6b0570a8cc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "#Evaluating log-likelihood with Variational Autoencoders 2.2\n",
        "\n",
        "valid_log_px = importance_sampling(model, valid_loader, 128, 784, 100, 200)\n",
        "test_log_px = importance_sampling(model, test_loader, 128, 784, 100, 200)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.UpsamplingBilinear2d is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "zh5wl0p1MecK",
        "colab_type": "code",
        "outputId": "6e930068-752e-4fc9-dcdc-e2fc29fe53ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "test(20, valid_loader)\n",
        "print('for the validation set')\n",
        "\n",
        "test(20, test_loader),\n",
        "print('for the test set')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.UpsamplingBilinear2d is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2016: UserWarning: Using a target size (torch.Size([128, 784])) that is different to the input size (torch.Size([128, 1, 28, 28])) is deprecated. Please ensure they have the same size.\n",
            "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2016: UserWarning: Using a target size (torch.Size([16, 784])) that is different to the input size (torch.Size([16, 1, 28, 28])) is deprecated. Please ensure they have the same size.\n",
            "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "====> average per-instance ELBO: -95.6372\n",
            "for the validation set\n",
            "====> average per-instance ELBO: -94.8347\n",
            "for the test set\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "o8NM7YJJPBa_",
        "colab_type": "code",
        "outputId": "d712b06c-7ea5-40bf-bddb-d04964baea96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "print('Evaluating log-likelihood with Variational Autoencoders 2.2')\n",
        "print('validation set log-likelihood estimate: ', torch.mean(valid_log_px).cpu().numpy())\n",
        "print('test set log-likelihood estimate: ', torch.mean(test_log_px).cpu().numpy())\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating log-likelihood with Variational Autoencoders 2.2\n",
            "validation set log-likelihood estimate:  -90.208725\n",
            "test set log-likelihood estimate:  -89.45522\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GRH8Wjz1PLK3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}