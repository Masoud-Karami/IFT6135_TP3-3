{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda:0\n",
      "Using downloaded and verified file: svhn/train_32x32.mat\n",
      "Using downloaded and verified file: svhn/test_32x32.mat\n",
      "------- EPOCH 0 --------\n",
      "Training example 0 / 1031. DiscLoss: 3.21, GenLoss: 0.11\n",
      "Training example 100 / 1031. DiscLoss: -697.92, GenLoss: 110.47\n",
      "Training example 200 / 1031. DiscLoss: -1029.39, GenLoss: 137.95\n",
      "Training example 300 / 1031. DiscLoss: -3824.33, GenLoss: 320.36\n",
      "Training example 400 / 1031. DiscLoss: -3907.61, GenLoss: 750.18\n",
      "Training example 500 / 1031. DiscLoss: -701.75, GenLoss: 720.77\n",
      "Training example 600 / 1031. DiscLoss: -1650.31, GenLoss: 681.50\n",
      "Training example 700 / 1031. DiscLoss: -5404.58, GenLoss: 694.01\n",
      "Training example 800 / 1031. DiscLoss: -17733.75, GenLoss: 1424.11\n",
      "Training example 900 / 1031. DiscLoss: -21979.57, GenLoss: 2300.45\n",
      "Training example 1000 / 1031. DiscLoss: -10096.63, GenLoss: 2336.72\n",
      "------- EPOCH 1 --------\n",
      "Training example 0 / 1031. DiscLoss: -366.88, GenLoss: 155.65\n",
      "Training example 100 / 1031. DiscLoss: -42996.80, GenLoss: 3717.11\n",
      "Training example 200 / 1031. DiscLoss: -29619.35, GenLoss: 4533.68\n",
      "Training example 300 / 1031. DiscLoss: 631.31, GenLoss: 4288.05\n",
      "Training example 400 / 1031. DiscLoss: -38.77, GenLoss: 4293.05\n",
      "Training example 500 / 1031. DiscLoss: -194.38, GenLoss: 4276.48\n",
      "Training example 600 / 1031. DiscLoss: -171.43, GenLoss: 4259.63\n",
      "Training example 700 / 1031. DiscLoss: -246.29, GenLoss: 4243.24\n",
      "Training example 800 / 1031. DiscLoss: -266.67, GenLoss: 4217.92\n",
      "Training example 900 / 1031. DiscLoss: -402.98, GenLoss: 4210.22\n",
      "Training example 1000 / 1031. DiscLoss: -565.47, GenLoss: 4184.27\n",
      "------- EPOCH 2 --------\n",
      "Training example 0 / 1031. DiscLoss: -5.85, GenLoss: 209.31\n",
      "Training example 100 / 1031. DiscLoss: -1018.23, GenLoss: 4183.48\n",
      "Training example 200 / 1031. DiscLoss: -1907.23, GenLoss: 4203.68\n",
      "Training example 300 / 1031. DiscLoss: -3012.21, GenLoss: 4230.66\n",
      "Training example 400 / 1031. DiscLoss: -4743.59, GenLoss: 4293.32\n",
      "Training example 500 / 1031. DiscLoss: -7556.00, GenLoss: 4412.25\n",
      "Training example 600 / 1031. DiscLoss: -10099.70, GenLoss: 4611.07\n",
      "Training example 700 / 1031. DiscLoss: -17597.43, GenLoss: 4891.77\n",
      "Training example 800 / 1031. DiscLoss: -31032.53, GenLoss: 5448.45\n",
      "Training example 900 / 1031. DiscLoss: 2615.32, GenLoss: 5381.65\n",
      "Training example 1000 / 1031. DiscLoss: -1383.13, GenLoss: 5307.15\n",
      "------- EPOCH 3 --------\n",
      "Training example 0 / 1031. DiscLoss: -53.05, GenLoss: 261.34\n",
      "Training example 100 / 1031. DiscLoss: -21792.71, GenLoss: 5393.65\n",
      "Training example 200 / 1031. DiscLoss: -57808.74, GenLoss: 6415.16\n",
      "Training example 300 / 1031. DiscLoss: -84128.22, GenLoss: 7844.17\n",
      "Training example 400 / 1031. DiscLoss: -103663.30, GenLoss: 9321.29\n",
      "Training example 500 / 1031. DiscLoss: -120255.66, GenLoss: 10802.94\n",
      "Training example 600 / 1031. DiscLoss: 5317.49, GenLoss: 9978.32\n",
      "Training example 700 / 1031. DiscLoss: -675.46, GenLoss: 9732.16\n",
      "Training example 800 / 1031. DiscLoss: -4240.70, GenLoss: 9700.98\n",
      "Training example 900 / 1031. DiscLoss: -17338.58, GenLoss: 9779.43\n",
      "Training example 1000 / 1031. DiscLoss: -64844.41, GenLoss: 10285.23\n",
      "------- EPOCH 4 --------\n",
      "Training example 0 / 1031. DiscLoss: -1051.66, GenLoss: 554.24\n",
      "Training example 100 / 1031. DiscLoss: 15330.21, GenLoss: 10266.36\n",
      "Training example 200 / 1031. DiscLoss: 5164.02, GenLoss: 9694.26\n",
      "Training example 300 / 1031. DiscLoss: 2320.16, GenLoss: 9774.67\n",
      "Training example 400 / 1031. DiscLoss: 1844.00, GenLoss: 9837.60\n",
      "Training example 500 / 1031. DiscLoss: 2434.59, GenLoss: 9582.31\n",
      "Training example 600 / 1031. DiscLoss: 1264.39, GenLoss: 9621.55\n",
      "Training example 700 / 1031. DiscLoss: 53.46, GenLoss: 9732.89\n",
      "Training example 800 / 1031. DiscLoss: -325.16, GenLoss: 9699.82\n",
      "Training example 900 / 1031. DiscLoss: -344.65, GenLoss: 9636.64\n",
      "Training example 1000 / 1031. DiscLoss: -94.83, GenLoss: 9577.15\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sat Apr 20 14:41:19 2019\n",
    "\n",
    "@author: karm2204\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "References:\n",
    "\"\"\"\n",
    "#%%\n",
    "\n",
    "# https://github.com/pytorch/examples/blob/master/dcgan/main.py\n",
    "# https://discuss.pytorch.org/t/gradient-penalty-with-respect-to-the-network-parameters/11944/2\n",
    "# https://pytorch.org/tutorials/beginner/pytorch_with_examples.html\n",
    "# https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html\n",
    "\n",
    "#%%\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import dataset\n",
    "\n",
    "\n",
    "#%%\n",
    "\n",
    "def get_data_loader(dataset_location, batch_size):\n",
    "    trainvalid = torchvision.datasets.SVHN(\n",
    "        dataset_location, split='train',\n",
    "        download=True,\n",
    "        transform=image_transform\n",
    "    )\n",
    "\n",
    "    trainset_size = int(len(trainvalid) * 0.9)\n",
    "    trainset, validset = dataset.random_split(\n",
    "        trainvalid,\n",
    "        [trainset_size, len(trainvalid) - trainset_size]\n",
    "    )\n",
    "\n",
    "    train = torch.utils.data.DataLoader(\n",
    "        trainset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=2\n",
    "    )\n",
    "\n",
    "    valid = torch.utils.data.DataLoader(\n",
    "        validset,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    test = torch.utils.data.DataLoader(\n",
    "        torchvision.datasets.SVHN(\n",
    "            dataset_location, split='test',\n",
    "            download=True,\n",
    "            transform=image_transform\n",
    "        ),\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    return train, valid, test\n",
    "\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "#%%     \n",
    "class Generator(nn.Module):\n",
    "    \"\"\" Generator. Input is noise and latent variables, output is a generated\n",
    "    image.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d(100, 512, kernel_size = 4, stride = 1, padding = 0, bias = False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ELU(),\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size = 4, stride = 2, padding = 1, bias = False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ELU(),\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size = 4, stride = 2, padding = 1, bias = False),\n",
    "            nn.BatchNorm2d(64 * 2),\n",
    "            nn.ELU(),\n",
    "            nn.ConvTranspose2d(128, 3, kernel_size = 4, stride = 2, padding = 1, bias = False)\n",
    "        )\n",
    "\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input_):\n",
    "        input_ = input_.view(input_.size(0), -1, 1, 1)\n",
    "        input_ = self.main(input_)\n",
    "        input_ = self.activation(input_)\n",
    "        return input_\n",
    "\n",
    "#%%\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\" Discriminator. Input is an image (real or generated), output is\n",
    "    P(generated), continuous latent variables, discrete latent variables.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(3, 128, kernel_size = 4, stride = 2, padding = 1, bias = False),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(128, 256, kernel_size = 4, stride = 2, padding = 1, bias = False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(256, 512, kernel_size = 4, stride = 2, padding = 1, bias = False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(512, 1, kernel_size = 4, stride = 1, padding = 0, bias = False),\n",
    "        )\n",
    "\n",
    "    def forward(self, image: torch.Tensor) -> torch.Tensor:\n",
    "        input_ = self.main(image)\n",
    "        input_ = input_.view(-1, 1).squeeze(1)\n",
    "        return input_\n",
    "\n",
    "#%%\n",
    "class GAN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.latent_dim = 100\n",
    "        self.generator = Generator()\n",
    "        self.discriminator = Discriminator()\n",
    "        self.lambda_gp = 10.0\n",
    "#%%   \n",
    "def compute_gradient_penalty(x, y, G):\n",
    "    '''\n",
    "        Random weight term for interpolation between real and fake samples\n",
    "        Get random interpolation between real x and fake y samples\n",
    "    '''\n",
    "    alpha = torch.rand((x.size(0), 1, 1, 1), device = x.device)\n",
    "    lin_interpol = alpha * x + (1-alpha) * y\n",
    "    lin_interpol.requires_grad_(True)\n",
    "    # need a fake grad output\n",
    "    output = G.discriminator(lin_interpol)\n",
    "    # Get gradient w.r.t. interpolates\n",
    "    gradients = torch.autograd.grad(\n",
    "        outputs=output,\n",
    "        inputs=lin_interpol,\n",
    "        grad_outputs=torch.ones_like(output),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True,\n",
    "    )\n",
    "    gradients = gradients[0]\n",
    "    gradient = gradients.view(gradients.size(0), -1)\n",
    "    norm_2 = gradient.norm(p=2, dim=1)\n",
    "    gradient_penalty = ((norm_2 - 1).pow(2)).mean()\n",
    "    return gradient_penalty\n",
    "#%% \n",
    "# https://pytorch.org/tutorials/beginner/pytorch_with_examples.html \n",
    "\n",
    "def visual_samples(G, dimensions, device, svhn_loader, step=0):\n",
    "    # Generate new images\n",
    "    z = torch.randn(64, dimensions, device=device)\n",
    "    generated = G.generator(z)\n",
    "    #debug\n",
    "    torchvision.utils.save_image(generated, 'images/gan/gan-gen.png', normalize=False)\n",
    "    #torchvision.utils.save_image(generated, f\"images/gan/3_1gan-generated-{step}.png\", normalize=False)\n",
    "def disentangled_representation(G, dimensions, device, epsilon = 3):\n",
    "    #Sample from prior p(z) which is a Std Normal\n",
    "    z = torch.randn(dimensions, device=device)\n",
    "    \n",
    "    #Copy this tensor times its number of dimensions and make perturbations on each dimension\n",
    "    #The first element is the original sample\n",
    "    z = z.repeat(dimensions+1, 1)\n",
    "    for i, sample in enumerate(z[1:]):\n",
    "        sample[i] += epsilon\n",
    "\n",
    "    generated = G.generator(z)\n",
    "    torchvision.utils.save_image(generated, 'images/gan/plus_eps.png', normalize=False)\n",
    "\n",
    "    #Do the same with the negative epsilon\n",
    "    epsilon = -2*epsilon\n",
    "    for i, sample in enumerate(z[1:]):\n",
    "        sample[i] += epsilon\n",
    "\n",
    "    #Make a batch of the pertubations and pass it through the generator\n",
    "    generated = G.generator(z)\n",
    "    torchvision.utils.save_image(generated, 'images/gan/nega_eps.png', normalize=False)\n",
    "    \n",
    "#%%\n",
    "    \n",
    "def interpolation(G, dimensions, device):\n",
    "    # Interpolate in the latent space between z_0 and z_1\n",
    "    z_0 = torch.randn(1,dimensions, device=device)\n",
    "    z_1 = torch.randn(1,dimensions, device=device)\n",
    "    z_a = torch.zeros([11,dimensions], device=device)\n",
    "\n",
    "    for i in range(11):\n",
    "        a = i/10\n",
    "        z_a[i] = a*z_0 + (1-a)*z_1\n",
    "\n",
    "    generated = G.generator(z_a)\n",
    "    torchvision.utils.save_image(generated, 'images/gan/latent.png', normalize = False)\n",
    "    \n",
    "    # Interpolate in the data space between x_0 and x_1\n",
    "    x_0 = G.generator(z_0)\n",
    "    x_1 = G.generator(z_1)\n",
    "    x_a = torch.zeros(11,x_0.size()[1],x_0.size()[2],x_0.size()[3], device = device)\n",
    "\n",
    "    for i in range(11):\n",
    "        a = i/10\n",
    "        x_a[i] = torch.lerp(x_0, x_1, a)\n",
    "\n",
    "    torchvision.utils.save_image(x_a, 'images/gan/data.png', normalize = False)\n",
    "\n",
    "\n",
    "def save_images(img_dir: str):\n",
    "    import os\n",
    "    G = GAN()\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    G.load_state_dict(torch.load('GAN_q#3_save.pth', map_location = device))\n",
    "    G = G.to(device)\n",
    "    G.eval()\n",
    "    \n",
    "    for p in G.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    for i in range(10):\n",
    "        print(i)\n",
    "        latents = torch.randn(100, 100, device=device)\n",
    "        images = G.generator(latents)\n",
    "        os.makedirs(f\"{img_dir}/img/\", exist_ok=True)\n",
    "        for j, image in enumerate(images):\n",
    "            filename = f\"{img_dir}/img/{i * 100 + j:03d}.png\"\n",
    "            torchvision.utils.save_image(image, filename, normalize=False)\n",
    "\n",
    "#%%\n",
    "if __name__ == '__main__':\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Running on {device}\")\n",
    "    \n",
    "    G = GAN()\n",
    "    G = G.to(device)\n",
    "    G.train()\n",
    "\n",
    "    gen_step = 5\n",
    "\n",
    "    D_optimizer = torch.optim.Adam(G.discriminator.parameters(), lr=1e-4, betas=(0.5, 0.999))\n",
    "    G_optimizer = torch.optim.Adam(G.generator.parameters(), lr=1e-4, betas=(0.5, 0.999))\n",
    "\n",
    "    train, valid, test = get_data_loader(\"svhn\", 64)\n",
    "    \n",
    "    try: \n",
    "        G.load_state_dict(torch.load('GAN_q#3_save.pth', map_location=device))\n",
    "        print('----Using saved model----')\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        for epoch in range(5):\n",
    "            print(f\"------- EPOCH {epoch} --------\")\n",
    "\n",
    "            running_loss_d = 0\n",
    "            running_loss_g = 0\n",
    "            \n",
    "            for i, (img, _) in enumerate(train):\n",
    "                G.train()\n",
    "\n",
    "                # Training the discriminator\n",
    "                D_optimizer.zero_grad()                \n",
    "                img = img.to(device)\n",
    "                latents = torch.randn([img.shape[0], G.latent_dim], device=device)\n",
    "                fakes = G.generator(latents).detach()\n",
    "                \n",
    "                fakes_score = G.discriminator(fakes)\n",
    "                fakes_score_mean = fakes_score.mean()\n",
    "                fakes_score_mean.backward()\n",
    "\n",
    "                reals_score = G.discriminator(img)\n",
    "                reals_score_mean = -reals_score.mean()\n",
    "                reals_score_mean.backward()\n",
    "                loss = fakes_score_mean + reals_score_mean\n",
    "            \n",
    "                grad_penalty = G.lambda_gp * compute_gradient_penalty(img, fakes, G)\n",
    "                grad_penalty.backward()\n",
    "                loss += grad_penalty\n",
    "                \n",
    "                D_optimizer.step()\n",
    "                running_loss_d += loss\n",
    "\n",
    "                # training the generator\n",
    "                if i % gen_step == 0:\n",
    "                    G_optimizer.zero_grad()\n",
    "                    latents = torch.randn([img.shape[0], G.latent_dim], device=device)\n",
    "                    fakes = G.generator(latents)\n",
    "\n",
    "                    fakes_score = G.discriminator(fakes)\n",
    "                    fakes_score_mean = -fakes_score.mean()\n",
    "                    fakes_score_mean.backward()\n",
    "\n",
    "                    G_optimizer.step()\n",
    "                    running_loss_g += fakes_score_mean\n",
    "                    \n",
    "                if(i%10 == 0):\n",
    "                    visual_samples(G, 100, device, test)\n",
    "\n",
    "                if i % 100 == 0:\n",
    "                    print(f\"Training example {i} / {len(train)}. DiscLoss: {running_loss_d:.2f}, GenLoss: {running_loss_g:.2f}\")\n",
    "                    running_loss_d = 0\n",
    "                    running_loss_g = 0\n",
    "        \n",
    "        torch.save(G.state_dict(), 'GAN_q#3_save.pth')\n",
    "\n",
    "    dimensions = 100\n",
    "        \n",
    "    G.eval()\n",
    "    #3_1 Visual samples\n",
    "    visual_samples(G, dimensions, device, test)\n",
    "\n",
    "    #3_2 Disentangled representation\n",
    "    disentangled_representation(G, dimensions, device, epsilon=10)\n",
    "\n",
    "    #3_3 Interpolation\n",
    "    interpolation(G, dimensions, device)\n",
    "\n",
    "    img_dir = \"images/gan/fid\"\n",
    "    save_images(img_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_fastai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
