{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VAE_Q2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "a-HwxN4Iyg_j",
        "colab_type": "code",
        "outputId": "258abe2f-a6d8-4b8e-d436-6f1e91bf427c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Tue Apr 16 09:52:14 2019\n",
        "\n",
        "@author: karm2204\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "#####         https://chrisorm.github.io/VAE-pyt.html\n",
        "#             Variational Autoencoder in Pytorch\n",
        "#             https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/03-advanced/variational_autoencoder/main.py\n",
        "#             https://github.com/bobchennan/VAE_NBP/blob/master/vae_dp.py\n",
        "#             https://github.com/pytorch/examples/blob/master/vae/main.py\n",
        "\n",
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets\n",
        "from torchvision.utils import save_image\n",
        "from torch.autograd import Variable\n",
        "from sklearn.mixture import BayesianGaussianMixture\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import argparse\n",
        "from torchvision.datasets import utils\n",
        "import torch.utils.data as data_utils\n",
        "import torch\n",
        "import os\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from torch.nn.modules import upsampling\n",
        "from torch.functional import F\n",
        "from torch.optim import Adam\n",
        "\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.set_printoptions(precision=8)\n",
        "\n",
        "\n",
        "# Hyper-parameters\n",
        "batch_size = 128\n",
        "learning_rate = 3e-4\n",
        "image_size = 784\n",
        "h_dim = 400\n",
        "z_dim = 100\n",
        "num_epochs = 20\n",
        "\n",
        "\n",
        "#%%\n",
        "\n",
        "def get_data_loader(dataset_location, batch_size):\n",
        "    URL = \"http://www.cs.toronto.edu/~larocheh/public/datasets/binarized_mnist/\"\n",
        "    # start processing\n",
        "    def lines_to_np_array(lines):\n",
        "        return np.array([[int(i) for i in line.split()] for line in lines])\n",
        "    splitdata = []\n",
        "    for splitname in [\"train\", \"valid\", \"test\"]:\n",
        "        filename = \"binarized_mnist_%s.amat\" % splitname\n",
        "        filepath = os.path.join(dataset_location, filename)\n",
        "        utils.download_url(URL + filename, dataset_location)\n",
        "        with open(filepath) as f:\n",
        "            lines = f.readlines()\n",
        "        x = lines_to_np_array(lines).astype('float32')\n",
        "        x = x.reshape(x.shape[0], 1, 28, 28)\n",
        "        # pytorch data loader\n",
        "        dataset = data_utils.TensorDataset(torch.from_numpy(x))\n",
        "        dataset_loader = data_utils.DataLoader(x, batch_size=batch_size, shuffle=splitname == \"train\")\n",
        "        splitdata.append(dataset_loader)\n",
        "    return splitdata\n",
        "\n",
        "train_loader, valid_loader, test_loader = get_data_loader(\"binarized_mnist\", batch_size)\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "for x in train_loader:\n",
        "    plt.imshow(x[0, 0])\n",
        "    break\n",
        "    \n",
        "torch.cuda.memory_allocated(device)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using downloaded and verified file: binarized_mnist/binarized_mnist_train.amat\n",
            "Using downloaded and verified file: binarized_mnist/binarized_mnist_valid.amat\n",
            "Using downloaded and verified file: binarized_mnist/binarized_mnist_test.amat\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npaKMXyrK+KWijF8qyvilov4LoJ+ebxDxILYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "sLyvHhhGKshB",
        "colab_type": "code",
        "outputId": "727242f4-602c-4f32-b1b5-46b5284134e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "next(enumerate(train_loader))[1].size()\n",
        "torch.cuda.memory_allocated(device)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "GUfU7LW-1Jut",
        "colab_type": "code",
        "outputId": "c039597d-1745-4093-ee39-d37299fdedef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#%%\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, image_size=784, h_dim=400, z_dim=100):\n",
        "        super(VAE, self).__init__()\n",
        "        \n",
        "#         self.encoder = nn.Sequential(nn.Linear(image_size, h_dim),\\\n",
        "#                                 nn.ReLU()\\\n",
        "#                                )\n",
        "        self.encoder= nn.Sequential(nn.Conv2d(1,32,3),\\\n",
        "                                    nn.ELU(),\\\n",
        "                                    nn.AvgPool2d(2,2),\\\n",
        "                                    nn.Conv2d(32,64,3),\\\n",
        "                                    nn.ELU(),\\\n",
        "                                    nn.AvgPool2d(2,2),\\\n",
        "                                    nn.Conv2d(64,256,5),\\\n",
        "                                    nn.ELU(),\\\n",
        "                                    )\n",
        "#         self.fc_1 = nn.Linear(image_size, h_dim)\n",
        "        self.fc_1 = nn.Linear(256, z_dim)\n",
        "        self.fc_2 = nn.Linear(256, z_dim)\n",
        "\n",
        "        self.fc_3 = nn.Linear(z_dim, 256)\n",
        "#         self.fc_5 = nn.Linear(h_dim, image_size)\n",
        "        self.decoder= nn.Sequential(nn.ELU(),\\\n",
        "                                    nn.Conv2d(256,64,5, padding = 4),\\\n",
        "                                    nn.ELU(),\\\n",
        "                                    nn.UpsamplingBilinear2d(scale_factor=2),\\\n",
        "                                    nn.Conv2d(64, 32, 3, padding=2),\\\n",
        "                                    nn.ELU(),\\\n",
        "                                    nn.UpsamplingBilinear2d(scale_factor=2),\\\n",
        "                                    nn.Conv2d(32, 16, 3, padding=2),\\\n",
        "                                    nn.ELU(),\\\n",
        "                                    nn.Conv2d(16, 1, 3, padding=2),\\\n",
        "                                    nn.Sigmoid()\n",
        "                                    )\n",
        "        \n",
        "    \"\"\" Encode a batch of samples, and return posterior parameters for each point.\"\"\"    \n",
        "    def encode(self, x):\n",
        "#         h_1 = F.relu(self.fc_1(x))\n",
        "      h_1 = self.encoder(x)\n",
        "      return self.fc_1(h_1.view(-1,256)), self.fc_2(h_1.view(-1,256))\n",
        "\n",
        "\n",
        "    \"\"\" Reparameterisation trick to sample z values. \n",
        "        This is stochastic during training,  and returns the mode during evaluation.\n",
        "        For each training sample (we get 128 batched at a time)\n",
        "        - take the current learned mu, stddev for each of the z_dim \n",
        "        (in the pytorch VAE example, this is 20, z_dim = 20)\n",
        "          dimensions and draw a random sample from that distribution\n",
        "        - the whole network is trained so that these randomly drawn\n",
        "          samples decode to output that looks like the input\n",
        "        - which will mean that the std, mu will be learned\n",
        "          *distributions* that correctly encode the inputs\n",
        "        - due to the additional KLD term (see loss_function() below)\n",
        "          the distribution will tend to unit Gaussians\n",
        "        Parameters\n",
        "        ----------\n",
        "        mu : [128, z_dim] mean matrix\n",
        "        logvar : [128, z_dim] variance matrix\n",
        "        Returns\n",
        "        -------\n",
        "        During training random sample from the learned ZDIMS-dimensional\n",
        "        normal distribution; during inference its mean.\n",
        "        \"\"\"\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(logvar/2)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "\n",
        "    \"\"\" Decode a batch of latent variables\"\"\"\n",
        "    def decode(self, z):\n",
        "    #        h_3 = F.relu(self.fc_4(z))\n",
        "    #        return F.sigmoid(self.fc_5(h_3))\n",
        "        h_2 = self.fc_3(z).view(-1,256,1,1)\n",
        "        h_3 = self.decoder(h_2)\n",
        "        return h_3\n",
        "\n",
        "\n",
        "    \"\"\" Takes a batch of samples, encodes them, and then decodes them again to compare.\"\"\"\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decode(z), mu, logvar\n",
        "torch.cuda.memory_allocated(device)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "ywvLbrAtzHaM",
        "colab_type": "code",
        "outputId": "cd21d515-123a-45ea-b177-cb09f7fa9514",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2312
        }
      },
      "cell_type": "code",
      "source": [
        "#%%\n",
        "model = VAE().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\"\"\" ELBO assuming entries of x are binary variables, with closed form KLD.\"\"\"\n",
        "def loss_function(x_reconst, x, mu, logvar):\n",
        "    bce = F.binary_cross_entropy(x_reconst, x.view(-1, 784), reduction='sum')\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    # Normalise by same number of elements as in reconstruction\n",
        "    # KLD /= x.view(-1, image_size).data.shape[0] * image_size\n",
        "    return bce + KLD\n",
        "#%%\n",
        "\n",
        "# ----------\n",
        "#  Train\n",
        "# ----------\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    log_interval = 100\n",
        "    for batch_idx, data in enumerate(train_loader):\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        recon_batch, mu, logvar = model(data)\n",
        "        loss = loss_function(recon_batch, data, mu, logvar)\n",
        "        loss.backward()\n",
        "        train_loss += loss.item()\n",
        "        optimizer.step()\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\t Loss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset), 100. *\n",
        "                batch_idx / len(train_loader), -loss.item() / len(data)\n",
        "            ))\n",
        "\n",
        "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
        "        epoch, -train_loss / len(train_loader.dataset)))\n",
        "\n",
        "#%%\n",
        "\n",
        "# ----------\n",
        "#  Test\n",
        "# ----------\n",
        "def test(epoch, data_loader):\n",
        "    model.eval()\n",
        "    valid_loss = 0\n",
        "    # ind = np.arange(x.shape[0])\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(data_loader):\n",
        "            data = data.to(device)\n",
        "#           test_data = torch.from_numpy(test_data[np.random.choice(ind, size=batch_size)])\n",
        "#           test_data = Variable(test_data, requires_grad=False)\n",
        "            reconst_batch, mu, logvar = model(data)\n",
        "            valid_loss += loss_function(reconst_batch, data, mu, logvar).item()\n",
        "            if i == 0:\n",
        "                n = min(data.size(0), 28)\n",
        "                comparison = torch.cat([data[:n],\n",
        "                                        reconst_batch.view(128, 1, 28, 28)[:n]])\n",
        "#                 save_image(comparison.cpu(),\n",
        "#                          'results/reconstruction_' + str(epoch) + '.png', nrow=n)\n",
        "#            print(data.view(batch_size, 2,2)[:n])\n",
        "#            print(reconst_batch.view(batch_size, 2,2)[:n])\n",
        "            \n",
        "            \n",
        "    valid_loss /= len(data_loader.dataset)\n",
        "    print('====> average per-instance ELBO: {:.4f}'.format(-valid_loss))\n",
        "        \n",
        "#%%    \n",
        "if __name__ == \"__main__\":\n",
        "    for epoch in range(1, 21):\n",
        "        train(epoch)\n",
        "        test(epoch, valid_loader)\n",
        "        # 64 sets of random z_dim-float vectors, i.e. 64 locations / MNIST\n",
        "        # digits in latent space\n",
        "        with torch.no_grad():\n",
        "            sample = torch.randn(128, z_dim).to(device)\n",
        "            sample = model.decode(sample).cpu()\n",
        "#             save_image(sample.view(64, 1, 28, 28),\n",
        "#                        'results/sample_' + str(epoch) + '.png')\n",
        "    torch.save(model.state_dict(), 'vae.pth')            \n",
        "            "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.UpsamplingBilinear2d is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2016: UserWarning: Using a target size (torch.Size([128, 784])) that is different to the input size (torch.Size([128, 1, 28, 28])) is deprecated. Please ensure they have the same size.\n",
            "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/50000 (0%)]\t Loss: -535.012939\n",
            "Train Epoch: 1 [12800/50000 (26%)]\t Loss: -202.062790\n",
            "Train Epoch: 1 [25600/50000 (51%)]\t Loss: -187.348358\n",
            "Train Epoch: 1 [38400/50000 (77%)]\t Loss: -158.149841\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2016: UserWarning: Using a target size (torch.Size([80, 784])) that is different to the input size (torch.Size([80, 1, 28, 28])) is deprecated. Please ensure they have the same size.\n",
            "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "====> Epoch: 1 Average loss: -207.8293\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2016: UserWarning: Using a target size (torch.Size([16, 784])) that is different to the input size (torch.Size([16, 1, 28, 28])) is deprecated. Please ensure they have the same size.\n",
            "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "====> average per-instance ELBO: -153.6128\n",
            "Train Epoch: 2 [0/50000 (0%)]\t Loss: -148.042557\n",
            "Train Epoch: 2 [12800/50000 (26%)]\t Loss: -149.029510\n",
            "Train Epoch: 2 [25600/50000 (51%)]\t Loss: -142.686905\n",
            "Train Epoch: 2 [38400/50000 (77%)]\t Loss: -132.644852\n",
            "====> Epoch: 2 Average loss: -138.7451\n",
            "====> average per-instance ELBO: -128.7206\n",
            "Train Epoch: 3 [0/50000 (0%)]\t Loss: -123.249817\n",
            "Train Epoch: 3 [12800/50000 (26%)]\t Loss: -125.146965\n",
            "Train Epoch: 3 [25600/50000 (51%)]\t Loss: -123.295410\n",
            "Train Epoch: 3 [38400/50000 (77%)]\t Loss: -117.819740\n",
            "====> Epoch: 3 Average loss: -121.2870\n",
            "====> average per-instance ELBO: -116.4545\n",
            "Train Epoch: 4 [0/50000 (0%)]\t Loss: -116.749435\n",
            "Train Epoch: 4 [12800/50000 (26%)]\t Loss: -120.709442\n",
            "Train Epoch: 4 [25600/50000 (51%)]\t Loss: -118.880753\n",
            "Train Epoch: 4 [38400/50000 (77%)]\t Loss: -112.087929\n",
            "====> Epoch: 4 Average loss: -113.1490\n",
            "====> average per-instance ELBO: -110.9085\n",
            "Train Epoch: 5 [0/50000 (0%)]\t Loss: -114.576019\n",
            "Train Epoch: 5 [12800/50000 (26%)]\t Loss: -109.151207\n",
            "Train Epoch: 5 [25600/50000 (51%)]\t Loss: -112.207512\n",
            "Train Epoch: 5 [38400/50000 (77%)]\t Loss: -108.921150\n",
            "====> Epoch: 5 Average loss: -108.6806\n",
            "====> average per-instance ELBO: -107.0754\n",
            "Train Epoch: 6 [0/50000 (0%)]\t Loss: -104.745155\n",
            "Train Epoch: 6 [12800/50000 (26%)]\t Loss: -108.841003\n",
            "Train Epoch: 6 [25600/50000 (51%)]\t Loss: -113.001434\n",
            "Train Epoch: 6 [38400/50000 (77%)]\t Loss: -103.338593\n",
            "====> Epoch: 6 Average loss: -106.0258\n",
            "====> average per-instance ELBO: -105.4856\n",
            "Train Epoch: 7 [0/50000 (0%)]\t Loss: -109.463142\n",
            "Train Epoch: 7 [12800/50000 (26%)]\t Loss: -104.216125\n",
            "Train Epoch: 7 [25600/50000 (51%)]\t Loss: -104.857498\n",
            "Train Epoch: 7 [38400/50000 (77%)]\t Loss: -102.747498\n",
            "====> Epoch: 7 Average loss: -104.1222\n",
            "====> average per-instance ELBO: -103.8585\n",
            "Train Epoch: 8 [0/50000 (0%)]\t Loss: -101.072754\n",
            "Train Epoch: 8 [12800/50000 (26%)]\t Loss: -99.147987\n",
            "Train Epoch: 8 [25600/50000 (51%)]\t Loss: -102.819901\n",
            "Train Epoch: 8 [38400/50000 (77%)]\t Loss: -103.103416\n",
            "====> Epoch: 8 Average loss: -102.6973\n",
            "====> average per-instance ELBO: -102.5965\n",
            "Train Epoch: 9 [0/50000 (0%)]\t Loss: -102.726173\n",
            "Train Epoch: 9 [12800/50000 (26%)]\t Loss: -106.639305\n",
            "Train Epoch: 9 [25600/50000 (51%)]\t Loss: -106.124947\n",
            "Train Epoch: 9 [38400/50000 (77%)]\t Loss: -100.665161\n",
            "====> Epoch: 9 Average loss: -101.5292\n",
            "====> average per-instance ELBO: -101.3431\n",
            "Train Epoch: 10 [0/50000 (0%)]\t Loss: -97.712204\n",
            "Train Epoch: 10 [12800/50000 (26%)]\t Loss: -101.904068\n",
            "Train Epoch: 10 [25600/50000 (51%)]\t Loss: -103.565704\n",
            "Train Epoch: 10 [38400/50000 (77%)]\t Loss: -101.126663\n",
            "====> Epoch: 10 Average loss: -100.5931\n",
            "====> average per-instance ELBO: -100.5591\n",
            "Train Epoch: 11 [0/50000 (0%)]\t Loss: -95.838326\n",
            "Train Epoch: 11 [12800/50000 (26%)]\t Loss: -100.412720\n",
            "Train Epoch: 11 [25600/50000 (51%)]\t Loss: -99.671944\n",
            "Train Epoch: 11 [38400/50000 (77%)]\t Loss: -102.172928\n",
            "====> Epoch: 11 Average loss: -99.8017\n",
            "====> average per-instance ELBO: -99.7721\n",
            "Train Epoch: 12 [0/50000 (0%)]\t Loss: -96.880920\n",
            "Train Epoch: 12 [12800/50000 (26%)]\t Loss: -101.054802\n",
            "Train Epoch: 12 [25600/50000 (51%)]\t Loss: -101.657791\n",
            "Train Epoch: 12 [38400/50000 (77%)]\t Loss: -100.324219\n",
            "====> Epoch: 12 Average loss: -99.1177\n",
            "====> average per-instance ELBO: -99.4873\n",
            "Train Epoch: 13 [0/50000 (0%)]\t Loss: -103.641571\n",
            "Train Epoch: 13 [12800/50000 (26%)]\t Loss: -101.357460\n",
            "Train Epoch: 13 [25600/50000 (51%)]\t Loss: -98.427994\n",
            "Train Epoch: 13 [38400/50000 (77%)]\t Loss: -99.393021\n",
            "====> Epoch: 13 Average loss: -98.4673\n",
            "====> average per-instance ELBO: -98.5981\n",
            "Train Epoch: 14 [0/50000 (0%)]\t Loss: -96.780823\n",
            "Train Epoch: 14 [12800/50000 (26%)]\t Loss: -95.742081\n",
            "Train Epoch: 14 [25600/50000 (51%)]\t Loss: -94.507721\n",
            "Train Epoch: 14 [38400/50000 (77%)]\t Loss: -100.443001\n",
            "====> Epoch: 14 Average loss: -98.0297\n",
            "====> average per-instance ELBO: -98.1125\n",
            "Train Epoch: 15 [0/50000 (0%)]\t Loss: -99.433449\n",
            "Train Epoch: 15 [12800/50000 (26%)]\t Loss: -94.117989\n",
            "Train Epoch: 15 [25600/50000 (51%)]\t Loss: -101.154526\n",
            "Train Epoch: 15 [38400/50000 (77%)]\t Loss: -96.716660\n",
            "====> Epoch: 15 Average loss: -97.5079\n",
            "====> average per-instance ELBO: -97.9016\n",
            "Train Epoch: 16 [0/50000 (0%)]\t Loss: -97.595306\n",
            "Train Epoch: 16 [12800/50000 (26%)]\t Loss: -98.309807\n",
            "Train Epoch: 16 [25600/50000 (51%)]\t Loss: -98.970299\n",
            "Train Epoch: 16 [38400/50000 (77%)]\t Loss: -99.272865\n",
            "====> Epoch: 16 Average loss: -97.0108\n",
            "====> average per-instance ELBO: -97.3413\n",
            "Train Epoch: 17 [0/50000 (0%)]\t Loss: -96.184799\n",
            "Train Epoch: 17 [12800/50000 (26%)]\t Loss: -95.671066\n",
            "Train Epoch: 17 [25600/50000 (51%)]\t Loss: -92.831429\n",
            "Train Epoch: 17 [38400/50000 (77%)]\t Loss: -93.954163\n",
            "====> Epoch: 17 Average loss: -96.6737\n",
            "====> average per-instance ELBO: -96.9510\n",
            "Train Epoch: 18 [0/50000 (0%)]\t Loss: -99.591454\n",
            "Train Epoch: 18 [12800/50000 (26%)]\t Loss: -97.364212\n",
            "Train Epoch: 18 [25600/50000 (51%)]\t Loss: -96.306961\n",
            "Train Epoch: 18 [38400/50000 (77%)]\t Loss: -93.863243\n",
            "====> Epoch: 18 Average loss: -96.2984\n",
            "====> average per-instance ELBO: -96.6687\n",
            "Train Epoch: 19 [0/50000 (0%)]\t Loss: -98.913231\n",
            "Train Epoch: 19 [12800/50000 (26%)]\t Loss: -93.587708\n",
            "Train Epoch: 19 [25600/50000 (51%)]\t Loss: -96.232162\n",
            "Train Epoch: 19 [38400/50000 (77%)]\t Loss: -97.338715\n",
            "====> Epoch: 19 Average loss: -95.9099\n",
            "====> average per-instance ELBO: -96.0266\n",
            "Train Epoch: 20 [0/50000 (0%)]\t Loss: -97.200974\n",
            "Train Epoch: 20 [12800/50000 (26%)]\t Loss: -97.373383\n",
            "Train Epoch: 20 [25600/50000 (51%)]\t Loss: -96.946945\n",
            "Train Epoch: 20 [38400/50000 (77%)]\t Loss: -98.961159\n",
            "====> Epoch: 20 Average loss: -95.6281\n",
            "====> average per-instance ELBO: -96.0403\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bDQ3dpFMI9vT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Question 2.1\n",
        "\n",
        "The average per-instance ELBO at the bottom is the average per-instance ELBO on the validaton set."
      ]
    },
    {
      "metadata": {
        "id": "k5jgsPekJzRy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "outputId": "70d906a6-2a82-42c9-e94c-46bf9fc96204"
      },
      "cell_type": "code",
      "source": [
        "print(test(20, valid_loader))\n",
        "print(test(20, test_loader))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.UpsamplingBilinear2d is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2016: UserWarning: Using a target size (torch.Size([128, 784])) that is different to the input size (torch.Size([128, 1, 28, 28])) is deprecated. Please ensure they have the same size.\n",
            "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2016: UserWarning: Using a target size (torch.Size([16, 784])) that is different to the input size (torch.Size([16, 1, 28, 28])) is deprecated. Please ensure they have the same size.\n",
            "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "====> average per-instance ELBO: -95.9370\n",
            "None\n",
            "====> average per-instance ELBO: -95.2331\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BndjAQXcLhkE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Train a VAE 2.1\n",
        "The validation set loss = -95.8960.\n",
        "\n",
        "Train a VAE 2.2 \n",
        "The test set loss = -95.3129."
      ]
    },
    {
      "metadata": {
        "id": "ilFxgXH4-yTV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Evaluating log-likelihood with Variational Autoencoders 2.1\n",
        "\n",
        "def importance_sampling_minibatch(model, images, samples):\n",
        "  K = 200\n",
        "  hidden_size = 100\n",
        "  minibatch_size = 128\n",
        "  image_dim = 28\n",
        "  image_size = 784\n",
        "  images.to(device)\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    mean_val = torch.mean(samples, dim = 1)\n",
        "    sigma_val = torch.std(samples, dim = 1)\n",
        "\n",
        "    #two distributions, one standard and one displaced \n",
        "    standard = torch.distributions.normal.Normal(torch.zeros(min(minibatch_size,mean_val.size(0)),hidden_size).cuda(),\\\n",
        "                                                 torch.ones(min(minibatch_size,mean_val.size(0)),hidden_size).cuda())\n",
        "    displaced = torch.distributions.normal.Normal(mean_val, sigma_val)\n",
        "\n",
        "    #sample z x 200 from displaced distribution(mean and s.d. from encoder run on data)\n",
        "    samples = [displaced.sample(sample_shape=torch.Size()) for i in range(K)]\n",
        "\n",
        "    #p and q are (200, 128,100)\n",
        "    #density values for each samples, for each minibatch, for each uncorrelated z_i\n",
        "    log_p_samples = torch.stack([standard.log_prob(samples[i].data) for i in range(len(samples))])\n",
        "    log_q_samples = torch.stack([displaced.log_prob(samples[i].data) for i in range(len(samples))])\n",
        "\n",
        "    #torch.Size([200, 128, 784]) reconstructions of each sample/minibatch/image\n",
        "    reconstructions = torch.stack([model.decode(samples[i].data).view(-1,image_size) for i in range(K)])\n",
        "\n",
        "    #p of x given z computed with Binary cross entropy \n",
        "    log_p_x_given_z = ((images.view(-1,image_size) * torch.log(torch.clamp(reconstructions.data, 1e-9, 1))) + \\\n",
        "                       ((1.0-images.view(-1,image_size))*torch.log(torch.clamp(1.0-reconstructions.data, 1e-9, 1))))\n",
        "     \n",
        "    #max prob is 1, so max log prob is log(200) for logsumexp trick: \n",
        "    return (-np.log(K) + torch.logsumexp(torch.sum(log_p_x_given_z, dim=-1) + torch.sum(log_p_samples, dim=-1) - \\\n",
        "                                         torch.sum(log_q_samples, dim=-1), 0))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MgpNleoGry9R",
        "colab_type": "code",
        "outputId": "cd8dffbc-fc64-4019-99b9-26fc5ad3fa64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        }
      },
      "cell_type": "code",
      "source": [
        "#Generating own samples for proof that importance_sampling_minibatch works properly\n",
        "temp_images = next(enumerate(valid_loader))[1].view(-1,784).cuda()\n",
        "temp_mu, temp_sigma = model.encode(temp_images.view(-1,1,28,28))\n",
        "temp_sigma = torch.exp(temp_sigma.data/2)\n",
        "\n",
        "standard = torch.distributions.normal.Normal(torch.zeros(128,100).cuda(), torch.ones(128,100).cuda())\n",
        "displaced = torch.distributions.normal.Normal(temp_mu, temp_sigma)\n",
        "samples = [displaced.sample(sample_shape=torch.Size()) for i in range(200)]\n",
        "samples = torch.stack(samples).permute(1,0,2)\n",
        "\n",
        "importance_sampling_minibatch(model, temp_images, samples)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.UpsamplingBilinear2d is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ -95.08141327,  -66.30560303, -115.36122131,  -73.09304047,\n",
              "         -88.20056152,  -96.84841919, -110.32038879,  -73.13786316,\n",
              "         -48.47890472,  -66.00440216,  -98.58109283,  -99.75592041,\n",
              "        -105.84049225,  -95.39425659,  -73.50405884,  -85.32853699,\n",
              "         -52.67161560,  -76.09992218, -111.20024109,  -85.44422150,\n",
              "         -76.08871460,  -84.06807709,  -99.21234894,  -96.05400085,\n",
              "        -106.54539490,  -53.15565109,  -93.13987732,  -45.27252579,\n",
              "        -115.82149506,  -83.04344177,  -44.85003281, -119.06233215,\n",
              "         -74.35660553, -117.96781921,  -53.21369934,  -93.72145844,\n",
              "        -109.42955017,  -95.52478027,  -56.68395233, -112.79746246,\n",
              "         -98.54703522, -102.74304962, -102.57942200,  -97.77036285,\n",
              "         -80.62921906,  -99.32622528,  -97.42871857, -130.07397461,\n",
              "        -119.04170990,  -86.39460754,  -77.14169312,  -45.61820221,\n",
              "        -112.63374329,  -60.35403061,  -62.39115143,  -84.58748627,\n",
              "         -40.97538757, -108.89315796,  -76.98439789,  -75.64583588,\n",
              "        -100.77989197,  -68.12083435, -115.89472198, -108.31932068,\n",
              "         -68.92427063,  -80.02117157,  -88.75521851,  -84.60824585,\n",
              "         -94.97452545, -102.88755035,  -79.69635010, -113.16310120,\n",
              "         -51.01211166,  -73.77658081,  -46.37341690, -117.79520416,\n",
              "         -83.92088318,  -44.96640778,  -85.69042969,  -71.17819977,\n",
              "         -99.44747162, -120.21200562, -118.47542572,  -88.78681183,\n",
              "         -94.07425690,  -94.14491272,  -97.99996185,  -86.79548645,\n",
              "         -78.71015930,  -88.28348541, -116.16948700,  -77.90174103,\n",
              "         -91.90807343, -112.99910736,  -98.78643036,  -93.73640442,\n",
              "         -81.11898804,  -73.96642303,  -60.28640747, -111.99761963,\n",
              "        -133.28765869, -105.84439087,  -79.83820343,  -87.88353729,\n",
              "         -95.45246124, -122.10479736,  -90.80863953,  -94.71398163,\n",
              "         -85.47784424,  -88.59786224,  -74.76592255,  -75.61008453,\n",
              "         -97.57463074,  -92.83667755,  -71.71700287,  -98.01527405,\n",
              "         -69.16067505,  -63.20585632,  -77.42979431, -102.71540070,\n",
              "         -86.35509491,  -90.26260376,  -92.89801025,  -80.66751862,\n",
              "        -122.04160309, -105.98185730, -113.12377167,  -70.86084747],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "AMT_isebFmLC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For more practical purposes, the following importance sampling function was used instead since it generates its own samples $z_{ik}$."
      ]
    },
    {
      "metadata": {
        "id": "1SNlHGb6Fk82",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def importance_sampling(trained_model, image_loader, minibatch_size, image_size, hidden_size, K):\n",
        "  \n",
        "  log_px = []\n",
        "  with torch.no_grad():\n",
        "\n",
        "    #forward pass through model with image set\n",
        "    for i, data in enumerate(image_loader):\n",
        "      data = data.to(device)\n",
        "      mean_val, log_var_val = model.encode(data)\n",
        "      images = data\n",
        "    #   mean_val_test = mean_val[0].data\n",
        "    #   log_var_val_test = log_var_val[0].data\n",
        "      sigma_val = torch.exp(log_var_val.data/2)\n",
        "\n",
        "      #two distributions, one standard and one displaced \n",
        "      standard = torch.distributions.normal.Normal(torch.zeros(min(minibatch_size,mean_val.size(0)),hidden_size).cuda(),\\\n",
        "                                                   torch.ones(min(minibatch_size,mean_val.size(0)),hidden_size).cuda())\n",
        "      displaced = torch.distributions.normal.Normal(mean_val, sigma_val)\n",
        "\n",
        "      #sample z x 200 from displaced distribution(mean and s.d. from encoder run on data)\n",
        "      #sample = displaced.sample(sample_shape=torch.Size())\n",
        "      samples = [displaced.sample(sample_shape=torch.Size()) for i in range(K)]\n",
        "\n",
        "      #p and q are (200, 128,100)\n",
        "      #density values for each samples, for each minibatch, for each uncorrelated z_i\n",
        "      log_p_samples = torch.stack([standard.log_prob(samples[i].data) for i in range(len(samples))])\n",
        "      log_q_samples = torch.stack([displaced.log_prob(samples[i].data) for i in range(len(samples))])\n",
        "\n",
        "      #torch.Size([200, 128, 784]) reconstructions of each sample/minibatch/image\n",
        "      reconstructions = torch.stack([model.decode(samples[i].data).view(-1,image_size) for i in range(K)])\n",
        "\n",
        "      #p of x given z computed with Binary cross entropy ################# REVIEW DIMENSIONS HERE #####################\n",
        "      log_p_x_given_z = ((images.view(-1,image_size) * torch.log(torch.clamp(reconstructions.data, 1e-9, 1))) + \\\n",
        "                         ((1.0-images.view(-1,image_size))*torch.log(torch.clamp(1.0-reconstructions.data, 1e-9, 1))))\n",
        "\n",
        "      log_px.append( (-np.log(K) + torch.logsumexp(torch.sum(log_p_x_given_z, dim=-1) + torch.sum(log_p_samples, dim=-1) - torch.sum(log_q_samples, dim=-1), 0)))\n",
        "\n",
        "    return torch.cat(log_px)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oL5ukEKLHKmC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "dba96217-e4ad-4ce1-ee93-c220283f28fb"
      },
      "cell_type": "code",
      "source": [
        "#Evaluating log-likelihood with Variational Autoencoders 2.2\n",
        "\n",
        "valid_log_px = importance_sampling(model, valid_loader, 128, 784, 100, 200)\n",
        "test_log_px = importance_sampling(model, test_loader, 128, 784, 100, 200)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.UpsamplingBilinear2d is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "zh5wl0p1MecK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "outputId": "4c029940-e5d3-4d4b-9772-19cca700fed5"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "test(20, valid_loader)\n",
        "print('for the validation set')\n",
        "\n",
        "test(20, test_loader),\n",
        "print('for the test set')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.UpsamplingBilinear2d is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2016: UserWarning: Using a target size (torch.Size([128, 784])) that is different to the input size (torch.Size([128, 1, 28, 28])) is deprecated. Please ensure they have the same size.\n",
            "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2016: UserWarning: Using a target size (torch.Size([16, 784])) that is different to the input size (torch.Size([16, 1, 28, 28])) is deprecated. Please ensure they have the same size.\n",
            "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "====> average per-instance ELBO: -96.0564\n",
            "for the validation set\n",
            "====> average per-instance ELBO: -95.2196\n",
            "for the test set\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "o8NM7YJJPBa_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "d0a94267-683b-46ed-a1d6-3555326b84c0"
      },
      "cell_type": "code",
      "source": [
        "print('Evaluating log-likelihood with Variational Autoencoders 2.2')\n",
        "print('validation set log-likelihood estimate: ', torch.mean(valid_log_px).cpu().numpy())\n",
        "print('test set log-likelihood estimate: ', torch.mean(test_log_px).cpu().numpy())\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating log-likelihood with Variational Autoencoders 2.2\n",
            "validation set log-likelihood estimate:  -90.5806\n",
            "test set log-likelihood estimate:  -89.80103\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GRH8Wjz1PLK3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}